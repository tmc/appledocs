{
  "abstract": [
    {
      "text": "Store video sample data in different formats, depending on the type of compression you use.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.qtff/documentation/quicktime-file-format",
        "doc://com.apple.qtff/documentation/QuickTime-File-Format/Media_data_atom_types",
        "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_media"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_sample_data"
  },
  "kind": "article",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "modules": [
      {
        "name": "QuickTime File Format"
      }
    ],
    "role": "article",
    "roleHeading": "Article",
    "title": "Video sample data"
  },
  "primaryContentSections": [
    {
      "content": [
        {
          "anchor": "Overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "The format of the data stored in video samples is completely dependent on the type of the compression used, as indicated in the video sample description. The following sections discuss some of the video encoding schemes supported by QuickTime.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Uncompressed-RGB",
          "level": 2,
          "text": "Uncompressed RGB",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Uncompressed RGB data is stored in a variety of different formats. The format used depends on the depth field of the video sample description. For all depths, the image data is padded on each scan line to ensure that each scan line begins on an even byte boundary.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "items": [
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "For depths of 1, 2, 4, and 8, the values stored are indexes into the color table specified in the color table ID field.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "For a depth of 16, the pixels are stored as 5-5-5 RGB values with the high bit of each 16-bit integer set to ",
                      "type": "text"
                    },
                    {
                      "code": "0",
                      "type": "codeVoice"
                    },
                    {
                      "text": ".",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "For a depth of 24, the pixels are stored packed together in RGB order.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "For a depth of 32, the pixels are stored with an 8-bit alpha channel, followed by 8-bit RGB components.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            }
          ],
          "type": "unorderedList"
        },
        {
          "inlineContent": [
            {
              "text": "RGB data can be stored in composite or planar format. Composite format stores the RGB data for each pixel contiguously, while planar format stores the R, G, and B data separately, so the RGB information for a given pixel is found using the same offset into multiple tables. For example, the data for two pixels could be represented in composite format as RGB-RGB or in planar format as RR-GG-BB.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Uncompressed-Y%C2%B4CbCr-including-yuv2",
          "level": 2,
          "text": "Uncompressed Y´CbCr (including yuv2)",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "The Y´CbCr color space is widely used for digital video. In this data format, luminance is stored as a single value (Y), and chrominance information is stored as two color-difference components (Cb and Cr). Cb is the difference between the blue component and a reference value; Cr is the difference between the red component and a reference value.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "This is commonly referred to as “YUV” format, with “U” standing-in for Cb and “V” standing-in for Cr. This usage is not strictly correct, as YUV, YIC, and Y´CbCr are distinct color models for PAL, NTSC, and digital video, but most Y´CbCr data formats and codecs are described or even named as some variant of “YUV.”",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The values of Y, Cb, and Cr can be represented using a variety of bit depths, trading off accuracy for file size. Similarly, the chrominance values can be subsampled, recording only one pixel’s color value out of two, for example, or averaging the color value of adjacent pixels. This subsampling is a form of compression, but if no additional lossy compression is performed on the sampled video, it is still referred to as “uncompressed” Y´CbCr video. In addition, a fourth component can be added to Y´CbCr video to record an alpha channel.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The number of components (Y´CbCr with or without alpha) and any subsampling are denoted using ratios of three or four numbers, such as 4:2:2 to indicate 4 bits of Y to 2 bits each of Cb and Cr (chroma subsampling), or 4:4:4 for equal storage of Y, Cb, and Cr (no subsampling), or 4:4:4:4 for Y´CbCr plus alpha with no subsampling. The ratios do not typically denote actual bit depths.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Uncompressed Y´CbCr video data is typically stored as follows:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "items": [
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Y´, Cb, and Cr components of each line are stored spatially left to right and temporally from earliest to latest.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "The lines of a field or frame are stored spatially top to bottom and temporally earliest to latest.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Y´ is an unsigned integer. Cb and Cr are twos-complement signed integers.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            }
          ],
          "type": "unorderedList"
        },
        {
          "inlineContent": [
            {
              "text": "The yuv2 stream, for example, is encoded in a series of 4-byte packets. Each packet represents two adjacent pixels on the same scan line. The bytes within each packet are ordered as follows:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "y0 u y1 v"
          ],
          "syntax": null,
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "code": "y0",
              "type": "codeVoice"
            },
            {
              "text": " is the luminance value for the left pixel; ",
              "type": "text"
            },
            {
              "code": "y1",
              "type": "codeVoice"
            },
            {
              "text": " the luminance for the right pixel. ",
              "type": "text"
            },
            {
              "code": "u",
              "type": "codeVoice"
            },
            {
              "text": " and ",
              "type": "text"
            },
            {
              "code": "v",
              "type": "codeVoice"
            },
            {
              "text": " are chromatic values that are shared by both pixels.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Accurate conversion between RGB and Y´CbCr color spaces requires a computation for each component of each pixel. An example conversion from yuv2 into RGB is represented by the following equations:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "r = 1.402 * v + y + .5",
            "",
            "g = y - .7143 * v - .3437 * u + .5",
            "",
            "b = 1.77 * u + y + .5"
          ],
          "syntax": null,
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "The ",
              "type": "text"
            },
            {
              "code": "r",
              "type": "codeVoice"
            },
            {
              "text": ", ",
              "type": "text"
            },
            {
              "code": "g",
              "type": "codeVoice"
            },
            {
              "text": ", and ",
              "type": "text"
            },
            {
              "code": "b",
              "type": "codeVoice"
            },
            {
              "text": " values range from ",
              "type": "text"
            },
            {
              "code": "0",
              "type": "codeVoice"
            },
            {
              "text": " to ",
              "type": "text"
            },
            {
              "code": "255",
              "type": "codeVoice"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The coefficients in these equations are derived from matrix operations and depend on the reference values used for the primary colors and for white. QuickTime uses canonical values for these reference coefficients based on published standards. The sample description extension for Y´CbCr formats includes a ",
              "type": "text"
            },
            {
              "code": "'colr'",
              "type": "codeVoice"
            },
            {
              "text": " atom, which contains indexes into a table of canonical references. This provides support for multiple video standards without opening the door to data entry errors for stored coefficient values. Refer to the published standards for the formulas and methods used to derive conversion coefficients from the table entries.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "JPEG",
          "level": 2,
          "text": "JPEG",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "QuickTime stores JPEG images according to the rules described in the ISO JPEG specification, document number DIS 10918-1.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "MPEG-4-Video",
          "level": 2,
          "text": "MPEG-4 Video",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "MPEG-4 video uses the ",
              "type": "text"
            },
            {
              "code": "'mp4v'",
              "type": "codeVoice"
            },
            {
              "text": " data format. The sample description requires the elementary stream descriptor (‘esds’) extension to the standard video sample description. If non-square pixels are used, the pixel aspect ratio (",
              "type": "text"
            },
            {
              "code": "'pasp'",
              "type": "codeVoice"
            },
            {
              "text": ") extension is also required. For details on these extensions, see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.qtff/documentation/quicktime-file-format/Pixel_aspect_ratio",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " and ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.qtff/documentation/quicktime-file-format/MPEG-4_elementary_stream_descriptor_atom",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "MPEG-4 video conforms to ISO/IEC documents 14496-1/2000(E) and 14496-2:1999/Amd.1:2000(E).",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Motion-JPEG",
          "level": 2,
          "text": "Motion-JPEG",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Motion-JPEG (M-JPEG) is a variant of the ISO JPEG specification for use with digital video streams. Instead of compressing an entire image into a single bitstream, Motion-JPEG compresses each video field separately, returning the resulting JPEG bitstreams consecutively in a single frame.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "There are two flavors of Motion-JPEG currently in use. These two formats differ based on their use of markers. Motion-JPEG format A supports markers; Motion-JPEG format B does not. The following paragraphs describe how QuickTime stores Motion-JPEG sample data.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Each field of Motion-JPEG format A fully complies with the ISO JPEG specification, and therefore supports application markers. QuickTime uses the APP1 marker to store control information, as follows (all of the fields are 32-bit integers):",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "items": [
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "Unpredictable; should be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Reserved",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "Identifies the data type; this field must be set to ",
                        "type": "text"
                      },
                      {
                        "code": "'mjpg'",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Tag",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The actual size of the image data for this field, in bytes.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Field size",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "Contains the size of the image data, including pad bytes. Some video hardware may append pad bytes to the image data; this field, along with the field size field, allows you to compute how many pad bytes were added.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Padded field size",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the start of the next field in the bitstream. This field should be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": " in the last field’s marker data.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Offset to next field",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the quantization table marker. If this field is set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ", check the image description for a default quantization table.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Quantization table offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the Huffman table marker. If this field is set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ", check the image description for a default Huffman table.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Huffman table offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset from the start of the field data to the start of image marker. This field should never be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Start of frame offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the start of the scan marker. This field should never be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Start of scan offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the start of the data stream. Typically, this immediately follows the start of scan data.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Start of data offset",
                    "type": "text"
                  }
                ]
              }
            }
          ],
          "type": "termList"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "The last two fields have been added since the original Motion-JPEG specification, and so they may be missing from some Motion-JPEG A files. You should check the length of the APP1 marker before using the start of scan offset and start of data offset fields.",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        },
        {
          "inlineContent": [
            {
              "text": "Motion-JPEG format B does not support markers. In place of the marker, therefore, QuickTime inserts a header at the beginning of the bitstream. Again, all of the fields are 32-bit integers.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "items": [
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "Unpredictable; should be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Reserved",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The data type; this field must be set to ",
                        "type": "text"
                      },
                      {
                        "code": "'mjpg'",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Tag",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The actual size of the image data for this field, in bytes.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Field size",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The size of the image data, including pad bytes. Some video hardware may append pad bytes to the image data; this field, along with the field size field, allows you to compute how many pad bytes were added.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Padded field size",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the start of the next field in the bitstream. This field should be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": " in the second field’s header data.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Offset to next field",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the quantization table. If this field is set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ", check the image description for a default quantization table.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Quantization table offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the Huffman table. If this field is set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ", check the image description for a default Huffman table.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Huffman table offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset from the start of the field data to the field’s image data. This field should never be set to ",
                        "type": "text"
                      },
                      {
                        "code": "0",
                        "type": "codeVoice"
                      },
                      {
                        "text": ".",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Start of frame offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the start of scan data.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Start of scan offset",
                    "type": "text"
                  }
                ]
              }
            },
            {
              "definition": {
                "content": [
                  {
                    "inlineContent": [
                      {
                        "text": "The offset, in bytes, from the start of the field data to the start of the data stream. Typically, this immediately follows the start of scan data.",
                        "type": "text"
                      }
                    ],
                    "type": "paragraph"
                  }
                ]
              },
              "term": {
                "inlineContent": [
                  {
                    "text": "Start of data offset",
                    "type": "text"
                  }
                ]
              }
            }
          ],
          "type": "termList"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "The last two fields were “reserved, must be set to zero” in the original Motion-JPEG specification.",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        },
        {
          "inlineContent": [
            {
              "text": "The Motion-JPEG format B header must be a multiple of 16 in size. When you add pad bytes to the header, set them to ",
              "type": "text"
            },
            {
              "code": "0",
              "type": "codeVoice"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Because Motion-JPEG format B does not support markers, the JPEG bitstream does not have ",
              "type": "text"
            },
            {
              "code": "NULL",
              "type": "codeVoice"
            },
            {
              "text": " bytes (",
              "type": "text"
            },
            {
              "code": "0x00",
              "type": "codeVoice"
            },
            {
              "text": ") inserted after data bytes that are set to ",
              "type": "text"
            },
            {
              "code": "0xFF",
              "type": "codeVoice"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.qtff/documentation/QuickTime-File-Format/Media_data_atom_types": {
      "abstract": [
        {
          "text": "Store different types of media data, including video, sound, subtitles, and more.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/QuickTime-File-Format/Media_data_atom_types",
      "kind": "article",
      "role": "collectionGroup",
      "title": "Media data atom types",
      "type": "topic",
      "url": "/documentation/quicktime-file-format/media_data_atom_types"
    },
    "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_media": {
      "abstract": [
        {
          "text": "Store compressed and uncompressed image data in QuickTime movies.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_media",
      "kind": "article",
      "role": "collectionGroup",
      "title": "Video media",
      "type": "topic",
      "url": "/documentation/quicktime-file-format/video_media"
    },
    "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_sample_description_extensions": {
      "abstract": [
        {
          "text": "Extend video sample descriptions by appending other atoms.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_sample_description_extensions",
      "kind": "article",
      "role": "collectionGroup",
      "title": "Video sample description extensions",
      "type": "topic",
      "url": "/documentation/quicktime-file-format/video_sample_description_extensions"
    },
    "doc://com.apple.qtff/documentation/quicktime-file-format": {
      "abstract": [
        {
          "text": "An object-oriented file format for the storage and exchange of digital media between devices, applications, and operating systems.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/quicktime-file-format",
      "kind": "symbol",
      "role": "collection",
      "title": "QuickTime File Format",
      "type": "topic",
      "url": "/documentation/quicktime-file-format"
    },
    "doc://com.apple.qtff/documentation/quicktime-file-format/MPEG-4_elementary_stream_descriptor_atom": {
      "abstract": [
        {
          "text": "A required extension to the video sample description for MPEG-4 video.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "identifier",
          "preciseIdentifier": "__docc_universal_symbol_reference_$MPEG-4_elementary_stream_descriptor_atom",
          "text": "MPEG-4 elementary stream descriptor atom ('esds')"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/quicktime-file-format/MPEG-4_elementary_stream_descriptor_atom",
      "kind": "symbol",
      "role": "symbol",
      "title": "MPEG-4 elementary stream descriptor atom ('esds')",
      "type": "topic",
      "url": "/documentation/quicktime-file-format/mpeg-4_elementary_stream_descriptor_atom"
    },
    "doc://com.apple.qtff/documentation/quicktime-file-format/Pixel_aspect_ratio": {
      "abstract": [
        {
          "text": "An extension that specifies the height-to-width ratio of pixels found in the video sample.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "identifier",
          "preciseIdentifier": "__docc_universal_symbol_reference_$Pixel_aspect_ratio",
          "text": "Pixel aspect ratio ('pasp')"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/quicktime-file-format/Pixel_aspect_ratio",
      "kind": "symbol",
      "role": "symbol",
      "title": "Pixel aspect ratio ('pasp')",
      "type": "topic",
      "url": "/documentation/quicktime-file-format/pixel_aspect_ratio"
    },
    "doc://com.apple.qtff/documentation/quicktime-file-format/Video_sample_description": {
      "abstract": [
        {
          "text": "An atom that contains information that defines how to interpret video media data.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "identifier",
          "preciseIdentifier": "__docc_universal_symbol_reference_$Video_sample_description",
          "text": "Video sample description ('stsd')"
        }
      ],
      "identifier": "doc://com.apple.qtff/documentation/quicktime-file-format/Video_sample_description",
      "kind": "symbol",
      "role": "symbol",
      "title": "Video sample description ('stsd')",
      "type": "topic",
      "url": "/documentation/quicktime-file-format/video_sample_description"
    }
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Storing-video-data",
      "generated": true,
      "identifiers": [
        "doc://com.apple.qtff/documentation/quicktime-file-format/Video_sample_description",
        "doc://com.apple.qtff/documentation/QuickTime-File-Format/Video_sample_description_extensions"
      ],
      "title": "Storing video data"
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/quicktime-file-format/video_sample_data"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    }
  ]
}
