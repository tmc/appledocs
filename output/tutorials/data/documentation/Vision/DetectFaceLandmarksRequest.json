{
  "abstract": [
    {
      "text": "An image-analysis request that finds facial features like eyes and mouth in an image.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest"
  },
  "kind": "symbol",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "externalID": "s:6Vision26DetectFaceLandmarksRequestV",
    "fragments": [
      {
        "kind": "keyword",
        "text": "struct"
      },
      {
        "kind": "text",
        "text": " "
      },
      {
        "kind": "identifier",
        "text": "DetectFaceLandmarksRequest"
      }
    ],
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "navigatorTitle": [
      {
        "kind": "identifier",
        "text": "DetectFaceLandmarksRequest"
      }
    ],
    "platforms": [
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iPadOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "Mac Catalyst",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "15.0",
        "name": "macOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "tvOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "2.0",
        "name": "visionOS",
        "unavailable": false
      }
    ],
    "role": "symbol",
    "roleHeading": "Structure",
    "symbolKind": "struct",
    "title": "DetectFaceLandmarksRequest"
  },
  "primaryContentSections": [
    {
      "declarations": [
        {
          "languages": [
            "swift"
          ],
          "platforms": [
            "iOS",
            "iPadOS",
            "Mac Catalyst",
            "macOS",
            "tvOS",
            "visionOS"
          ],
          "tokens": [
            {
              "kind": "keyword",
              "text": "struct"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "DetectFaceLandmarksRequest"
            }
          ]
        }
      ],
      "kind": "declarations"
    },
    {
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "By default, a request for face landmarks first locates all faces in the input image, then analyzes each to detect facial features.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "If you already located all the faces in an image, or want to detect landmarks in only a subset of the faces in the image, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceCaptureQualityRequest/inputFaceObservations",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " property to an array of ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/FaceObservation",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " objects representing the faces you want to analyze. You can either use face observations output by a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceRectanglesRequest",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " or manually create ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/FaceObservation",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " instances with the bounding boxes of the faces you want to analyze.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceCaptureQualityRequest": {
      "abstract": [
        {
          "text": "A request that produces a floating-point number that represents the capture quality of a face in a photo.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "DetectFaceCaptureQualityRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceCaptureQualityRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "DetectFaceCaptureQualityRequest"
        }
      ],
      "role": "symbol",
      "title": "DetectFaceCaptureQualityRequest",
      "type": "topic",
      "url": "/documentation/vision/detectfacecapturequalityrequest"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceCaptureQualityRequest/inputFaceObservations": {
      "abstract": [
        {
          "text": "An array of face-observation objects to process as part of the request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "inputFaceObservations"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision15FaceObservationV",
          "text": "FaceObservation"
        },
        {
          "kind": "text",
          "text": "]?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceCaptureQualityRequest/inputFaceObservations",
      "kind": "symbol",
      "role": "symbol",
      "title": "inputFaceObservations",
      "type": "topic",
      "url": "/documentation/vision/detectfacecapturequalityrequest/inputfaceobservations"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest": {
      "abstract": [
        {
          "text": "An image-analysis request that finds facial features like eyes and mouth in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "DetectFaceLandmarksRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "DetectFaceLandmarksRequest"
        }
      ],
      "role": "symbol",
      "title": "DetectFaceLandmarksRequest",
      "type": "topic",
      "url": "/documentation/vision/detectfacelandmarksrequest"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/Revision-swift.enum": {
      "abstract": [
        {
          "text": "A type that describes the algorithm or implementation that the request performs.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Revision"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/Revision-swift.enum",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "Revision"
        }
      ],
      "role": "symbol",
      "title": "DetectFaceLandmarksRequest.Revision",
      "type": "topic",
      "url": "/documentation/vision/detectfacelandmarksrequest/revision-swift.enum"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/init(_:)": {
      "abstract": [
        {
          "text": "Creates a face landmark detection request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "identifier",
          "text": "init"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision26DetectFaceLandmarksRequestV",
          "text": "DetectFaceLandmarksRequest"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision26DetectFaceLandmarksRequestV8RevisionO",
          "text": "Revision"
        },
        {
          "kind": "text",
          "text": "?)"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/init(_:)",
      "kind": "symbol",
      "role": "symbol",
      "title": "init(_:)",
      "type": "topic",
      "url": "/documentation/vision/detectfacelandmarksrequest/init(_:)"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/inputFaceObservations": {
      "abstract": [
        {
          "text": "An array of face-observation objects to process as part of the request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "inputFaceObservations"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision15FaceObservationV",
          "text": "FaceObservation"
        },
        {
          "kind": "text",
          "text": "]?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/inputFaceObservations",
      "kind": "symbol",
      "role": "symbol",
      "title": "inputFaceObservations",
      "type": "topic",
      "url": "/documentation/vision/detectfacelandmarksrequest/inputfaceobservations"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/revision-swift.property": {
      "abstract": [
        {
          "text": "The algorithm or implementation the request uses.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "revision"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision26DetectFaceLandmarksRequestV",
          "text": "DetectFaceLandmarksRequest"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision26DetectFaceLandmarksRequestV8RevisionO",
          "text": "Revision"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/revision-swift.property",
      "kind": "symbol",
      "role": "symbol",
      "title": "revision",
      "type": "topic",
      "url": "/documentation/vision/detectfacelandmarksrequest/revision-swift.property"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/supportedRevisions": {
      "abstract": [
        {
          "text": "The collection of revisions the request supports.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supportedRevisions"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision26DetectFaceLandmarksRequestV",
          "text": "DetectFaceLandmarksRequest"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision26DetectFaceLandmarksRequestV8RevisionO",
          "text": "Revision"
        },
        {
          "kind": "text",
          "text": "]"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/supportedRevisions",
      "kind": "symbol",
      "role": "symbol",
      "title": "supportedRevisions",
      "type": "topic",
      "url": "/documentation/vision/detectfacelandmarksrequest/supportedrevisions"
    },
    "doc://com.apple.vision/documentation/Vision/DetectFaceRectanglesRequest": {
      "abstract": [
        {
          "text": "A request that finds faces within an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "DetectFaceRectanglesRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectFaceRectanglesRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "DetectFaceRectanglesRequest"
        }
      ],
      "role": "symbol",
      "title": "DetectFaceRectanglesRequest",
      "type": "topic",
      "url": "/documentation/vision/detectfacerectanglesrequest"
    },
    "doc://com.apple.vision/documentation/Vision/DetectHumanRectanglesRequest": {
      "abstract": [
        {
          "text": "A request that finds rectangular regions that contain people in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "DetectHumanRectanglesRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectHumanRectanglesRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "DetectHumanRectanglesRequest"
        }
      ],
      "role": "symbol",
      "title": "DetectHumanRectanglesRequest",
      "type": "topic",
      "url": "/documentation/vision/detecthumanrectanglesrequest"
    },
    "doc://com.apple.vision/documentation/Vision/FaceObservation": {
      "abstract": [
        {
          "text": "An image-analysis request that identifies facial features in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "FaceObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/FaceObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "FaceObservation"
        }
      ],
      "role": "symbol",
      "title": "FaceObservation",
      "type": "topic",
      "url": "/documentation/vision/faceobservation"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest": {
      "abstract": [
        {
          "text": "A type for image-analysis requests that focus on a specific part of an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageProcessingRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageProcessingRequest"
        }
      ],
      "role": "symbol",
      "title": "ImageProcessingRequest",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-3f3f1": {
      "abstract": [
        {
          "text": "Performs the request on image data and produces observations.",
          "type": "text"
        }
      ],
      "defaultImplementations": 6,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "perform"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "on"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:10Foundation4DataV",
          "text": "Data"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "orientation"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@CGImagePropertyOrientation",
          "text": "CGImagePropertyOrientation"
        },
        {
          "kind": "text",
          "text": "?) "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "text": "Self"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision0A7RequestP6ResultQa",
          "text": "Result"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-3f3f1",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "perform(on:orientation:)",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest/perform(on:orientation:)-3f3f1"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-3hddl": {
      "abstract": [
        {
          "text": "Performs the request on a Core Media buffer and produces observations.",
          "type": "text"
        }
      ],
      "defaultImplementations": 6,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "perform"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "on"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@CMSampleBufferRef",
          "text": "CMSampleBuffer"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "orientation"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@CGImagePropertyOrientation",
          "text": "CGImagePropertyOrientation"
        },
        {
          "kind": "text",
          "text": "?) "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "text": "Self"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision0A7RequestP6ResultQa",
          "text": "Result"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-3hddl",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "perform(on:orientation:)",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest/perform(on:orientation:)-3hddl"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-80bya": {
      "abstract": [
        {
          "text": "Performs the request on an image URL and produces observations.",
          "type": "text"
        }
      ],
      "defaultImplementations": 6,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "perform"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "on"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:10Foundation3URLV",
          "text": "URL"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "orientation"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@CGImagePropertyOrientation",
          "text": "CGImagePropertyOrientation"
        },
        {
          "kind": "text",
          "text": "?) "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "text": "Self"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision0A7RequestP6ResultQa",
          "text": "Result"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-80bya",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "perform(on:orientation:)",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest/perform(on:orientation:)-80bya"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-85ex1": {
      "abstract": [
        {
          "text": "Performs the request on a Core Image image and produces observations.",
          "type": "text"
        }
      ],
      "defaultImplementations": 6,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "perform"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "on"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)CIImage",
          "text": "CIImage"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "orientation"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@CGImagePropertyOrientation",
          "text": "CGImagePropertyOrientation"
        },
        {
          "kind": "text",
          "text": "?) "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "text": "Self"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision0A7RequestP6ResultQa",
          "text": "Result"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-85ex1",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "perform(on:orientation:)",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest/perform(on:orientation:)-85ex1"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-qxxx": {
      "abstract": [
        {
          "text": "Performs the request on a Core Graphics image and produces observations.",
          "type": "text"
        }
      ],
      "defaultImplementations": 6,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "perform"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "on"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@CGImageRef",
          "text": "CGImage"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "orientation"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@CGImagePropertyOrientation",
          "text": "CGImagePropertyOrientation"
        },
        {
          "kind": "text",
          "text": "?) "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "text": "Self"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision0A7RequestP6ResultQa",
          "text": "Result"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-qxxx",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "perform(on:orientation:)",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest/perform(on:orientation:)-qxxx"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-xspx": {
      "abstract": [
        {
          "text": "Performs the request on a pixel buffer and produces observations.",
          "type": "text"
        }
      ],
      "defaultImplementations": 6,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "perform"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "on"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@CVPixelBufferRef",
          "text": "CVPixelBuffer"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "orientation"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@CGImagePropertyOrientation",
          "text": "CGImagePropertyOrientation"
        },
        {
          "kind": "text",
          "text": "?) "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "text": "Self"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision0A7RequestP6ResultQa",
          "text": "Result"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-xspx",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "perform(on:orientation:)",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest/perform(on:orientation:)-xspx"
    },
    "doc://com.apple.vision/documentation/Vision/VisionRequest": {
      "abstract": [
        {
          "text": "A type for image-analysis requests.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VisionRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VisionRequest"
        }
      ],
      "role": "symbol",
      "title": "VisionRequest",
      "type": "topic",
      "url": "/documentation/vision/visionrequest"
    },
    "doc://com.apple.vision/documentation/Vision/analyzing-a-selfie-and-visualizing-its-content": {
      "abstract": [
        {
          "text": "Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/analyzing-a-selfie-and-visualizing-its-content",
      "kind": "article",
      "role": "sampleCode",
      "title": "Analyzing a selfie and visualizing its content",
      "type": "topic",
      "url": "/documentation/vision/analyzing-a-selfie-and-visualizing-its-content"
    },
    "doc://com.externally.resolved.symbol/s:SH": {
      "abstract": [
        {
          "text": "A type that can be hashed into a `Hasher` to produce an integer hash value.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Hashable"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SQ",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SH",
      "kind": "symbol",
      "role": "symbol",
      "title": "Hashable",
      "type": "topic",
      "url": "/documentation/Swift/Hashable"
    },
    "doc://com.externally.resolved.symbol/s:SQ": {
      "abstract": [
        {
          "text": "A type that can be compared for value equality.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SQ",
      "kind": "symbol",
      "role": "symbol",
      "title": "Equatable",
      "type": "topic",
      "url": "/documentation/Swift/Equatable"
    },
    "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP": {
      "abstract": [
        {
          "text": "A type with a customized textual representation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CustomStringConvertible"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
      "kind": "symbol",
      "role": "symbol",
      "title": "CustomStringConvertible",
      "type": "topic",
      "url": "/documentation/Swift/CustomStringConvertible"
    },
    "doc://com.externally.resolved.symbol/s:s8SendableP": {
      "abstract": [
        {
          "text": "A thread-safe type whose values can be shared across arbitrary concurrent contexts without introducing a risk of data races.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Sendable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s8SendableP",
      "kind": "symbol",
      "role": "symbol",
      "title": "Sendable",
      "type": "topic",
      "url": "/documentation/Swift/Sendable"
    }
  },
  "relationshipsSections": [
    {
      "identifiers": [
        "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
        "doc://com.externally.resolved.symbol/s:SQ",
        "doc://com.externally.resolved.symbol/s:SH",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest",
        "doc://com.externally.resolved.symbol/s:s8SendableP",
        "doc://com.apple.vision/documentation/Vision/VisionRequest"
      ],
      "kind": "relationships",
      "title": "Conforms To",
      "type": "conformsTo"
    }
  ],
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Face-and-body-detection",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/analyzing-a-selfie-and-visualizing-its-content",
        "doc://com.apple.vision/documentation/Vision/DetectFaceRectanglesRequest",
        "doc://com.apple.vision/documentation/Vision/DetectFaceCaptureQualityRequest",
        "doc://com.apple.vision/documentation/Vision/DetectHumanRectanglesRequest"
      ],
      "title": "Face and body detection"
    }
  ],
  "topicSections": [
    {
      "anchor": "Creating-a-request",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/init(_:)"
      ],
      "title": "Creating a request"
    },
    {
      "anchor": "Getting-the-revision",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/revision-swift.property",
        "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/supportedRevisions",
        "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/Revision-swift.enum"
      ],
      "title": "Getting the revision"
    },
    {
      "anchor": "Inspecting-a-request",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/DetectFaceLandmarksRequest/inputFaceObservations"
      ],
      "title": "Inspecting a request"
    },
    {
      "anchor": "Performing-a-request",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-80bya",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-3f3f1",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-qxxx",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-xspx",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-3hddl",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest/perform(on:orientation:)-85ex1",
        "doc://com.apple.vision/documentation/Vision/FaceObservation"
      ],
      "title": "Performing a request"
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/detectfacelandmarksrequest"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    }
  ]
}
