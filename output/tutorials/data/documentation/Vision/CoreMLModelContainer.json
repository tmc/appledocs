{
  "abstract": [
    {
      "text": "A model container to use with an image-analysis request.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer"
  },
  "kind": "symbol",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "externalID": "s:6Vision20CoreMLModelContainerV",
    "fragments": [
      {
        "kind": "keyword",
        "text": "struct"
      },
      {
        "kind": "text",
        "text": " "
      },
      {
        "kind": "identifier",
        "text": "CoreMLModelContainer"
      }
    ],
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "navigatorTitle": [
      {
        "kind": "identifier",
        "text": "CoreMLModelContainer"
      }
    ],
    "platforms": [
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iPadOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "Mac Catalyst",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "15.0",
        "name": "macOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "tvOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "2.0",
        "name": "visionOS",
        "unavailable": false
      }
    ],
    "role": "symbol",
    "roleHeading": "Structure",
    "symbolKind": "struct",
    "title": "CoreMLModelContainer"
  },
  "primaryContentSections": [
    {
      "declarations": [
        {
          "languages": [
            "swift"
          ],
          "platforms": [
            "iOS",
            "iPadOS",
            "Mac Catalyst",
            "macOS",
            "tvOS",
            "visionOS"
          ],
          "tokens": [
            {
              "kind": "keyword",
              "text": "struct"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "CoreMLModelContainer"
            }
          ]
        }
      ],
      "kind": "declarations"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/ComputeStage": {
      "abstract": [
        {
          "text": "Types that represent the compute stage.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ComputeStage"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ComputeStage",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ComputeStage"
        }
      ],
      "role": "symbol",
      "title": "ComputeStage",
      "type": "topic",
      "url": "/documentation/vision/computestage"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer": {
      "abstract": [
        {
          "text": "A model container to use with an image-analysis request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CoreMLModelContainer"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "CoreMLModelContainer"
        }
      ],
      "role": "symbol",
      "title": "CoreMLModelContainer",
      "type": "topic",
      "url": "/documentation/vision/coremlmodelcontainer"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer/init(model:featureProvider:)": {
      "abstract": [],
      "fragments": [
        {
          "kind": "identifier",
          "text": "init"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "model"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)MLModel",
          "text": "MLModel"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "featureProvider"
        },
        {
          "kind": "text",
          "text": ": (any "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(pl)MLFeatureProvider",
          "text": "MLFeatureProvider"
        },
        {
          "kind": "text",
          "text": ")?) "
        },
        {
          "kind": "keyword",
          "text": "throws"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer/init(model:featureProvider:)",
      "kind": "symbol",
      "role": "symbol",
      "title": "init(model:featureProvider:)",
      "type": "topic",
      "url": "/documentation/vision/coremlmodelcontainer/init(model:featureprovider:)"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer/inputImageFeatureName": {
      "abstract": [
        {
          "text": "The name of the feature value that Vision sets from the request handler.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "inputImageFeatureName"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer/inputImageFeatureName",
      "kind": "symbol",
      "role": "symbol",
      "title": "inputImageFeatureName",
      "type": "topic",
      "url": "/documentation/vision/coremlmodelcontainer/inputimagefeaturename"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest/cropAndScaleAction": {
      "abstract": [
        {
          "text": "An optional setting that tells the Vision algorithm how to scale an input image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "cropAndScaleAction"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision23ImageCropAndScaleActionO",
          "text": "ImageCropAndScaleAction"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/cropAndScaleAction",
      "kind": "symbol",
      "role": "symbol",
      "title": "cropAndScaleAction",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest/cropandscaleaction"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest/modelContainer": {
      "abstract": [
        {
          "text": "The model to base the image analysis request on.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "modelContainer"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision20CoreMLModelContainerV",
          "text": "CoreMLModelContainer"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/modelContainer",
      "kind": "symbol",
      "role": "symbol",
      "title": "modelContainer",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest/modelcontainer"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest/supportedIdentifiers": {
      "abstract": [
        {
          "text": "The classification identifiers supported by the request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supportedIdentifiers"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        },
        {
          "kind": "text",
          "text": "]?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/supportedIdentifiers",
      "kind": "symbol",
      "role": "symbol",
      "title": "supportedIdentifiers",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest/supportedidentifiers"
    },
    "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction": {
      "abstract": [
        {
          "text": "A scale to apply to an input image before performing a request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageCropAndScaleAction"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageCropAndScaleAction"
        }
      ],
      "role": "symbol",
      "title": "ImageCropAndScaleAction",
      "type": "topic",
      "url": "/documentation/vision/imagecropandscaleaction"
    },
    "doc://com.externally.resolved.symbol/s:SH": {
      "abstract": [
        {
          "text": "A type that can be hashed into a `Hasher` to produce an integer hash value.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Hashable"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SQ",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SH",
      "kind": "symbol",
      "role": "symbol",
      "title": "Hashable",
      "type": "topic",
      "url": "/documentation/Swift/Hashable"
    },
    "doc://com.externally.resolved.symbol/s:SQ": {
      "abstract": [
        {
          "text": "A type that can be compared for value equality.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SQ",
      "kind": "symbol",
      "role": "symbol",
      "title": "Equatable",
      "type": "topic",
      "url": "/documentation/Swift/Equatable"
    },
    "doc://com.externally.resolved.symbol/s:s8SendableP": {
      "abstract": [
        {
          "text": "A thread-safe type whose values can be shared across arbitrary concurrent contexts without introducing a risk of data races.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Sendable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s8SendableP",
      "kind": "symbol",
      "role": "symbol",
      "title": "Sendable",
      "type": "topic",
      "url": "/documentation/Swift/Sendable"
    }
  },
  "relationshipsSections": [
    {
      "identifiers": [
        "doc://com.externally.resolved.symbol/s:SQ",
        "doc://com.externally.resolved.symbol/s:SH",
        "doc://com.externally.resolved.symbol/s:s8SendableP"
      ],
      "kind": "relationships",
      "title": "Conforms To",
      "type": "conformsTo"
    }
  ],
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Inspecting-a-request",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/CoreMLRequest/supportedIdentifiers",
        "doc://com.apple.vision/documentation/Vision/CoreMLRequest/modelContainer",
        "doc://com.apple.vision/documentation/Vision/ComputeStage",
        "doc://com.apple.vision/documentation/Vision/CoreMLRequest/cropAndScaleAction",
        "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction"
      ],
      "title": "Inspecting a request"
    }
  ],
  "topicSections": [
    {
      "anchor": "Creating-a-model-container",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer/init(model:featureProvider:)"
      ],
      "title": "Creating a model container"
    },
    {
      "anchor": "Getting-the-feature-name",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer/inputImageFeatureName"
      ],
      "title": "Getting the feature name"
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/coremlmodelcontainer"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    }
  ]
}
