{
  "abstract": [
    {
      "text": "An optional setting that tells the Vision algorithm how to scale an input image.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision",
        "doc://com.apple.vision/documentation/Vision/CoreMLRequest"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/cropAndScaleAction"
  },
  "kind": "symbol",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "externalID": "s:6Vision13CoreMLRequestV18cropAndScaleActionAA09ImageCropefG0Ovp",
    "fragments": [
      {
        "kind": "keyword",
        "text": "var"
      },
      {
        "kind": "text",
        "text": " "
      },
      {
        "kind": "identifier",
        "text": "cropAndScaleAction"
      },
      {
        "kind": "text",
        "text": ": "
      },
      {
        "kind": "typeIdentifier",
        "preciseIdentifier": "s:6Vision23ImageCropAndScaleActionO",
        "text": "ImageCropAndScaleAction"
      }
    ],
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "platforms": [
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iPadOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "Mac Catalyst",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "15.0",
        "name": "macOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "tvOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "2.0",
        "name": "visionOS",
        "unavailable": false
      }
    ],
    "role": "symbol",
    "roleHeading": "Instance Property",
    "symbolKind": "property",
    "title": "cropAndScaleAction"
  },
  "primaryContentSections": [
    {
      "declarations": [
        {
          "languages": [
            "swift"
          ],
          "platforms": [
            "iOS",
            "iPadOS",
            "Mac Catalyst",
            "macOS",
            "tvOS",
            "visionOS"
          ],
          "tokens": [
            {
              "kind": "keyword",
              "text": "var"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "cropAndScaleAction"
            },
            {
              "kind": "text",
              "text": ": "
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction",
              "kind": "typeIdentifier",
              "preciseIdentifier": "s:6Vision23ImageCropAndScaleActionO",
              "text": "ImageCropAndScaleAction"
            }
          ]
        }
      ],
      "kind": "declarations"
    },
    {
      "content": [
        {
          "anchor": "Discussion",
          "level": 2,
          "text": "Discussion",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Scaling an image ensures that the entire image fits into the algorithmâ€™s input image dimensions, which may require a change in aspect ratio. The default value is ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction/scaleToFill",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/ComputeStage": {
      "abstract": [
        {
          "text": "Types that represent the compute stage.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ComputeStage"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ComputeStage",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ComputeStage"
        }
      ],
      "role": "symbol",
      "title": "ComputeStage",
      "type": "topic",
      "url": "/documentation/vision/computestage"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer": {
      "abstract": [
        {
          "text": "A model container to use with an image-analysis request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CoreMLModelContainer"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "CoreMLModelContainer"
        }
      ],
      "role": "symbol",
      "title": "CoreMLModelContainer",
      "type": "topic",
      "url": "/documentation/vision/coremlmodelcontainer"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest": {
      "abstract": [
        {
          "text": "An image-analysis request that uses a Core ML model to process images.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CoreMLRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "CoreMLRequest"
        }
      ],
      "role": "symbol",
      "title": "CoreMLRequest",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest/cropAndScaleAction": {
      "abstract": [
        {
          "text": "An optional setting that tells the Vision algorithm how to scale an input image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "cropAndScaleAction"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision23ImageCropAndScaleActionO",
          "text": "ImageCropAndScaleAction"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/cropAndScaleAction",
      "kind": "symbol",
      "role": "symbol",
      "title": "cropAndScaleAction",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest/cropandscaleaction"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest/modelContainer": {
      "abstract": [
        {
          "text": "The model to base the image analysis request on.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "modelContainer"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision20CoreMLModelContainerV",
          "text": "CoreMLModelContainer"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/modelContainer",
      "kind": "symbol",
      "role": "symbol",
      "title": "modelContainer",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest/modelcontainer"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLRequest/supportedIdentifiers": {
      "abstract": [
        {
          "text": "The classification identifiers supported by the request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supportedIdentifiers"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        },
        {
          "kind": "text",
          "text": "]?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLRequest/supportedIdentifiers",
      "kind": "symbol",
      "role": "symbol",
      "title": "supportedIdentifiers",
      "type": "topic",
      "url": "/documentation/vision/coremlrequest/supportedidentifiers"
    },
    "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction": {
      "abstract": [
        {
          "text": "A scale to apply to an input image before performing a request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageCropAndScaleAction"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageCropAndScaleAction"
        }
      ],
      "role": "symbol",
      "title": "ImageCropAndScaleAction",
      "type": "topic",
      "url": "/documentation/vision/imagecropandscaleaction"
    },
    "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction/scaleToFill": {
      "abstract": [
        {
          "text": "An action that scales the image to fill the input dimensions and resizing it, if necessary.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "case"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "scaleToFill"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction/scaleToFill",
      "kind": "symbol",
      "role": "symbol",
      "title": "ImageCropAndScaleAction.scaleToFill",
      "type": "topic",
      "url": "/documentation/vision/imagecropandscaleaction/scaletofill"
    }
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Inspecting-a-request",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/CoreMLRequest/supportedIdentifiers",
        "doc://com.apple.vision/documentation/Vision/CoreMLRequest/modelContainer",
        "doc://com.apple.vision/documentation/Vision/CoreMLModelContainer",
        "doc://com.apple.vision/documentation/Vision/ComputeStage",
        "doc://com.apple.vision/documentation/Vision/ImageCropAndScaleAction"
      ],
      "title": "Inspecting a request"
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/coremlrequest/cropandscaleaction"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    }
  ]
}
