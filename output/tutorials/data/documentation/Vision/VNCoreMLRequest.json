{
  "abstract": [
    {
      "text": "An image-analysis request that uses a Core ML model to process images.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest"
  },
  "kind": "symbol",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "externalID": "c:objc(cs)VNCoreMLRequest",
    "fragments": [
      {
        "kind": "keyword",
        "text": "class"
      },
      {
        "kind": "text",
        "text": " "
      },
      {
        "kind": "identifier",
        "text": "VNCoreMLRequest"
      }
    ],
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "navigatorTitle": [
      {
        "kind": "identifier",
        "text": "VNCoreMLRequest"
      }
    ],
    "platforms": [
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "11.0",
        "name": "iOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "11.0",
        "name": "iPadOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "13.1",
        "name": "Mac Catalyst",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "10.13",
        "name": "macOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "11.0",
        "name": "tvOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "1.0",
        "name": "visionOS",
        "unavailable": false
      }
    ],
    "role": "symbol",
    "roleHeading": "Class",
    "symbolKind": "class",
    "title": "VNCoreMLRequest"
  },
  "primaryContentSections": [
    {
      "declarations": [
        {
          "languages": [
            "swift"
          ],
          "platforms": [
            "iOS",
            "iPadOS",
            "Mac Catalyst",
            "macOS",
            "tvOS",
            "visionOS"
          ],
          "tokens": [
            {
              "kind": "keyword",
              "text": "class"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "VNCoreMLRequest"
            }
          ]
        }
      ],
      "kind": "declarations"
    },
    {
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "The results array of a Core ML-based image analysis request contains a different observation type, depending on the kind of ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/CoreML/MLModel",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object you use:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "items": [
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "If the model predicts a single feature, the model’s ",
                      "type": "text"
                    },
                    {
                      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLModel/modelDescription",
                      "isActive": true,
                      "type": "reference"
                    },
                    {
                      "text": " object has a non-",
                      "type": "text"
                    },
                    {
                      "code": "nil",
                      "type": "codeVoice"
                    },
                    {
                      "text": " value for ",
                      "type": "text"
                    },
                    {
                      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLModelDescription/predictedFeatureName",
                      "isActive": true,
                      "type": "reference"
                    },
                    {
                      "text": " and Vision treats the model as a classifier. The results are ",
                      "type": "text"
                    },
                    {
                      "identifier": "doc://com.apple.vision/documentation/Vision/VNClassificationObservation",
                      "isActive": true,
                      "type": "reference"
                    },
                    {
                      "text": " objects.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "If the model’s outputs include at least one output with a feature type of ",
                      "type": "text"
                    },
                    {
                      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLFeatureType/image",
                      "isActive": true,
                      "type": "reference"
                    },
                    {
                      "text": ", Vision treats that model as an image-to-image model. The results are ",
                      "type": "text"
                    },
                    {
                      "identifier": "doc://com.apple.vision/documentation/Vision/VNPixelBufferObservation",
                      "isActive": true,
                      "type": "reference"
                    },
                    {
                      "text": " objects.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Otherwise, Vision treats the model as a general predictor model. The results are ",
                      "type": "text"
                    },
                    {
                      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLFeatureValueObservation",
                      "isActive": true,
                      "type": "reference"
                    },
                    {
                      "text": " objects.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            }
          ],
          "type": "unorderedList"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "",
                  "type": "text"
                },
                {
                  "text": " ",
                  "type": "text"
                },
                {
                  "text": "Vision forwards all ",
                  "type": "text"
                },
                {
                  "identifier": "doc://com.apple.vision/documentation/Vision/VNObservation/confidence",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": " values from Core ML models as-is and doesn’t normalize them to ",
                  "type": "text"
                },
                {
                  "code": "[0, 1]",
                  "type": "codeVoice"
                },
                {
                  "text": ".",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/CoreML/MLFeatureType/image": {
      "abstract": [
        {
          "text": "The type for image features and feature values.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "case"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "image"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLFeatureType/image",
      "kind": "symbol",
      "role": "symbol",
      "title": "MLFeatureType.image",
      "type": "topic",
      "url": "/documentation/CoreML/MLFeatureType/image"
    },
    "doc://com.apple.documentation/documentation/CoreML/MLModel": {
      "abstract": [
        {
          "text": "An encapsulation of all the details of your machine learning model.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "MLModel"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLModel",
      "kind": "symbol",
      "role": "symbol",
      "title": "MLModel",
      "type": "topic",
      "url": "/documentation/CoreML/MLModel"
    },
    "doc://com.apple.documentation/documentation/CoreML/MLModel/modelDescription": {
      "abstract": [
        {
          "text": "Model information you use at runtime during development, which Xcode also displays in its Core ML model editor view.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "modelDescription"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)MLModelDescription",
          "text": "MLModelDescription"
        },
        {
          "kind": "text",
          "text": " { "
        },
        {
          "kind": "keyword",
          "text": "get"
        },
        {
          "kind": "text",
          "text": " }"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLModel/modelDescription",
      "kind": "symbol",
      "role": "symbol",
      "title": "modelDescription",
      "type": "topic",
      "url": "/documentation/CoreML/MLModel/modelDescription"
    },
    "doc://com.apple.documentation/documentation/CoreML/MLModelDescription/predictedFeatureName": {
      "abstract": [
        {
          "text": "The name of the primary prediction feature output description.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "predictedFeatureName"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        },
        {
          "kind": "text",
          "text": "? { "
        },
        {
          "kind": "keyword",
          "text": "get"
        },
        {
          "kind": "text",
          "text": " }"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/CoreML/MLModelDescription/predictedFeatureName",
      "kind": "symbol",
      "role": "symbol",
      "title": "predictedFeatureName",
      "type": "topic",
      "url": "/documentation/CoreML/MLModelDescription/predictedFeatureName"
    },
    "doc://com.apple.documentation/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml": {
      "abstract": [
        {
          "text": "Crop and scale photos using the Vision framework and classify them with a Core ML model.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml",
      "kind": "article",
      "role": "sampleCode",
      "title": "Classifying Images with Vision and Core ML",
      "type": "topic",
      "url": "/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/VNClassificationObservation": {
      "abstract": [
        {
          "text": "An object that represents classification information that an image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNClassificationObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNClassificationObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNClassificationObservation"
        }
      ],
      "role": "symbol",
      "title": "VNClassificationObservation",
      "type": "topic",
      "url": "/documentation/vision/vnclassificationobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLFeatureValueObservation": {
      "abstract": [
        {
          "text": "An object that represents a collection of key-value information that a Core ML image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNCoreMLFeatureValueObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLFeatureValueObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNCoreMLFeatureValueObservation"
        }
      ],
      "role": "symbol",
      "title": "VNCoreMLFeatureValueObservation",
      "type": "topic",
      "url": "/documentation/vision/vncoremlfeaturevalueobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLModel": {
      "abstract": [
        {
          "text": "A container for the model to use with Vision requests.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNCoreMLModel"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLModel",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNCoreMLModel"
        }
      ],
      "role": "symbol",
      "title": "VNCoreMLModel",
      "type": "topic",
      "url": "/documentation/vision/vncoremlmodel"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest": {
      "abstract": [
        {
          "text": "An image-analysis request that uses a Core ML model to process images.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNCoreMLRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNCoreMLRequest"
        }
      ],
      "role": "symbol",
      "title": "VNCoreMLRequest",
      "type": "topic",
      "url": "/documentation/vision/vncoremlrequest"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/imageCropAndScaleOption": {
      "abstract": [
        {
          "text": "An optional setting that tells the Vision algorithm how to scale an input image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "imageCropAndScaleOption"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@E@VNImageCropAndScaleOption",
          "text": "VNImageCropAndScaleOption"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/imageCropAndScaleOption",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "imageCropAndScaleOption"
        }
      ],
      "role": "symbol",
      "title": "imageCropAndScaleOption",
      "type": "topic",
      "url": "/documentation/vision/vncoremlrequest/imagecropandscaleoption"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:)": {
      "abstract": [
        {
          "text": "Creates a model container to use with an image analysis request based on the model you provide.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "convenience"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "init"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "model"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNCoreMLModel",
          "text": "VNCoreMLModel"
        },
        {
          "kind": "text",
          "text": ")"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:)",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "initWithModel:"
        }
      ],
      "role": "symbol",
      "title": "init(model:)",
      "type": "topic",
      "url": "/documentation/vision/vncoremlrequest/init(model:)"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:completionHandler:)": {
      "abstract": [
        {
          "text": "Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "identifier",
          "text": "init"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "model"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNCoreMLModel",
          "text": "VNCoreMLModel"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "completionHandler"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNRequestCompletionHandler",
          "text": "VNRequestCompletionHandler"
        },
        {
          "kind": "text",
          "text": "?)"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:completionHandler:)",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "initWithModel:completionHandler:"
        }
      ],
      "role": "symbol",
      "title": "init(model:completionHandler:)",
      "type": "topic",
      "url": "/documentation/vision/vncoremlrequest/init(model:completionhandler:)"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/model": {
      "abstract": [
        {
          "text": "The model to base the image analysis request on.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "model"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNCoreMLModel",
          "text": "VNCoreMLModel"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/model",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "model"
        }
      ],
      "role": "symbol",
      "title": "model",
      "type": "topic",
      "url": "/documentation/vision/vncoremlrequest/model"
    },
    "doc://com.apple.vision/documentation/Vision/VNCoreMLRequestRevision1": {
      "abstract": [
        {
          "text": "A constant for specifying revision 1 of a Core ML request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNCoreMLRequestRevision1"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Si",
          "text": "Int"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNCoreMLRequestRevision1",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNCoreMLRequestRevision1"
        }
      ],
      "role": "symbol",
      "title": "VNCoreMLRequestRevision1",
      "type": "topic",
      "url": "/documentation/vision/vncoremlrequestrevision1"
    },
    "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest": {
      "abstract": [
        {
          "text": "The abstract superclass for image-analysis requests that focus on a specific part of an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNImageBasedRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNImageBasedRequest"
        }
      ],
      "role": "symbol",
      "title": "VNImageBasedRequest",
      "type": "topic",
      "url": "/documentation/vision/vnimagebasedrequest"
    },
    "doc://com.apple.vision/documentation/Vision/VNImageCropAndScaleOption": {
      "abstract": [
        {
          "text": "Options that define how Vision crops and scales an input-image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNImageCropAndScaleOption"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNImageCropAndScaleOption",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNImageCropAndScaleOption"
        }
      ],
      "role": "symbol",
      "title": "VNImageCropAndScaleOption",
      "type": "topic",
      "url": "/documentation/vision/vnimagecropandscaleoption"
    },
    "doc://com.apple.vision/documentation/Vision/VNObservation/confidence": {
      "abstract": [
        {
          "text": "The level of confidence in the observation’s accuracy.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "confidence"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNConfidence",
          "text": "VNConfidence"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNObservation/confidence",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "confidence"
        }
      ],
      "role": "symbol",
      "title": "confidence",
      "type": "topic",
      "url": "/documentation/vision/vnobservation/confidence"
    },
    "doc://com.apple.vision/documentation/Vision/VNPixelBufferObservation": {
      "abstract": [
        {
          "text": "An object that represents an image that an image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNPixelBufferObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNPixelBufferObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNPixelBufferObservation"
        }
      ],
      "role": "symbol",
      "title": "VNPixelBufferObservation",
      "type": "topic",
      "url": "/documentation/vision/vnpixelbufferobservation"
    },
    "doc://com.apple.vision/documentation/Vision/training-a-create-ml-model-to-classify-flowers": {
      "abstract": [
        {
          "text": "Train a flower classifier using Create ML in Swift Playgrounds, and apply the resulting model to real-time image classification using Vision.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/training-a-create-ml-model-to-classify-flowers",
      "kind": "article",
      "role": "sampleCode",
      "title": "Training a Create ML Model to Classify Flowers",
      "type": "topic",
      "url": "/documentation/vision/training-a-create-ml-model-to-classify-flowers"
    },
    "doc://com.externally.resolved.symbol/c:objc(pl)NSCopying": {
      "abstract": [
        {
          "text": "A protocol that objects adopt to provide functional copies of themselves.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "text",
          "text": "protocol "
        },
        {
          "kind": "identifier",
          "text": "NSCopying"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/c:objc(pl)NSCopying",
      "kind": "symbol",
      "role": "symbol",
      "title": "NSCopying",
      "type": "topic",
      "url": "/documentation/foundation/nscopying"
    },
    "doc://com.externally.resolved.symbol/c:objc(pl)NSObject": {
      "abstract": [
        {
          "text": "The group of methods that are fundamental to all Objective-C objects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "text",
          "text": "protocol "
        },
        {
          "kind": "identifier",
          "text": "NSObjectProtocol"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/c:objc(pl)NSObject",
      "kind": "symbol",
      "role": "symbol",
      "title": "NSObjectProtocol",
      "type": "topic",
      "url": "/documentation/objectivec/nsobjectprotocol"
    },
    "doc://com.externally.resolved.symbol/s:SH": {
      "abstract": [
        {
          "text": "A type that can be hashed into a `Hasher` to produce an integer hash value.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Hashable"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SQ",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SH",
      "kind": "symbol",
      "role": "symbol",
      "title": "Hashable",
      "type": "topic",
      "url": "/documentation/Swift/Hashable"
    },
    "doc://com.externally.resolved.symbol/s:SQ": {
      "abstract": [
        {
          "text": "A type that can be compared for value equality.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SQ",
      "kind": "symbol",
      "role": "symbol",
      "title": "Equatable",
      "type": "topic",
      "url": "/documentation/Swift/Equatable"
    },
    "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP": {
      "abstract": [
        {
          "text": "A type with a customized textual representation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CustomStringConvertible"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
      "kind": "symbol",
      "role": "symbol",
      "title": "CustomStringConvertible",
      "type": "topic",
      "url": "/documentation/Swift/CustomStringConvertible"
    },
    "doc://com.externally.resolved.symbol/s:s28CustomDebugStringConvertibleP": {
      "abstract": [
        {
          "text": "A type with a customized textual representation suitable for debugging purposes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CustomDebugStringConvertible"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s28CustomDebugStringConvertibleP",
      "kind": "symbol",
      "role": "symbol",
      "title": "CustomDebugStringConvertible",
      "type": "topic",
      "url": "/documentation/Swift/CustomDebugStringConvertible"
    },
    "doc://com.externally.resolved.symbol/s:s7CVarArgP": {
      "abstract": [
        {
          "text": "A type whose instances can be encoded, and appropriately passed, as elements of a C `va_list`.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CVarArg"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s7CVarArgP",
      "kind": "symbol",
      "role": "symbol",
      "title": "CVarArg",
      "type": "topic",
      "url": "/documentation/Swift/CVarArg"
    }
  },
  "relationshipsSections": [
    {
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest"
      ],
      "kind": "relationships",
      "title": "Inherits From",
      "type": "inheritsFrom"
    },
    {
      "identifiers": [
        "doc://com.externally.resolved.symbol/s:s7CVarArgP",
        "doc://com.externally.resolved.symbol/s:s28CustomDebugStringConvertibleP",
        "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
        "doc://com.externally.resolved.symbol/s:SQ",
        "doc://com.externally.resolved.symbol/s:SH",
        "doc://com.externally.resolved.symbol/c:objc(pl)NSCopying",
        "doc://com.externally.resolved.symbol/c:objc(pl)NSObject"
      ],
      "kind": "relationships",
      "title": "Conforms To",
      "type": "conformsTo"
    }
  ],
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Machine-learning-image-analysis",
      "generated": true,
      "identifiers": [
        "doc://com.apple.documentation/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml",
        "doc://com.apple.vision/documentation/Vision/training-a-create-ml-model-to-classify-flowers",
        "doc://com.apple.vision/documentation/Vision/VNClassificationObservation",
        "doc://com.apple.vision/documentation/Vision/VNPixelBufferObservation",
        "doc://com.apple.vision/documentation/Vision/VNCoreMLFeatureValueObservation"
      ],
      "title": "Machine learning image analysis"
    }
  ],
  "topicSections": [
    {
      "anchor": "Initializing-with-a-Core-ML-Model",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:)",
        "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:completionHandler:)",
        "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/model",
        "doc://com.apple.vision/documentation/Vision/VNCoreMLModel"
      ],
      "title": "Initializing with a Core ML Model"
    },
    {
      "anchor": "Configuring-Image-Options",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/imageCropAndScaleOption",
        "doc://com.apple.vision/documentation/Vision/VNImageCropAndScaleOption"
      ],
      "title": "Configuring Image Options"
    },
    {
      "anchor": "Identifying-Request-Revisions",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VNCoreMLRequestRevision1"
      ],
      "title": "Identifying Request Revisions"
    }
  ],
  "variantOverrides": [
    {
      "patch": [
        {
          "op": "replace",
          "path": "/identifier/interfaceLanguage",
          "value": "occ"
        },
        {
          "op": "replace",
          "path": "/metadata/platforms",
          "value": [
            {
              "beta": false,
              "deprecated": false,
              "introducedAt": "11.0",
              "name": "iOS",
              "unavailable": false
            },
            {
              "beta": false,
              "deprecated": false,
              "introducedAt": "11.0",
              "name": "iPadOS",
              "unavailable": false
            },
            {
              "beta": false,
              "deprecated": false,
              "introducedAt": "13.1",
              "name": "Mac Catalyst",
              "unavailable": false
            },
            {
              "beta": false,
              "deprecated": false,
              "introducedAt": "10.13",
              "name": "macOS",
              "unavailable": false
            },
            {
              "beta": false,
              "deprecated": false,
              "introducedAt": "11.0",
              "name": "tvOS",
              "unavailable": false
            },
            {
              "beta": false,
              "deprecated": false,
              "introducedAt": "1.0",
              "name": "visionOS",
              "unavailable": false
            }
          ]
        },
        {
          "op": "replace",
          "path": "/metadata/roleHeading",
          "value": "Class"
        },
        {
          "op": "replace",
          "path": "/metadata/title",
          "value": "VNCoreMLRequest"
        },
        {
          "op": "replace",
          "path": "/metadata/symbolKind",
          "value": "class"
        },
        {
          "op": "replace",
          "path": "/metadata/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/metadata/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/hierarchy",
          "value": {
            "paths": [
              [
                "doc://com.apple.documentation/documentation/technologies",
                "doc://com.apple.vision/documentation/Vision"
              ]
            ]
          }
        },
        {
          "op": "replace",
          "path": "/topicSections",
          "value": [
            {
              "anchor": "Initializing-with-a-Core-ML-Model",
              "identifiers": [
                "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:)",
                "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/init(model:completionHandler:)",
                "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/model",
                "doc://com.apple.vision/documentation/Vision/VNCoreMLModel"
              ],
              "title": "Initializing with a Core ML Model"
            },
            {
              "anchor": "Configuring-Image-Options",
              "identifiers": [
                "doc://com.apple.vision/documentation/Vision/VNCoreMLRequest/imageCropAndScaleOption",
                "doc://com.apple.vision/documentation/Vision/VNImageCropAndScaleOption"
              ],
              "title": "Configuring Image Options"
            },
            {
              "anchor": "Identifying-Request-Revisions",
              "identifiers": [
                "doc://com.apple.vision/documentation/Vision/VNCoreMLRequestRevision1"
              ],
              "title": "Identifying Request Revisions"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/relationshipsSections",
          "value": [
            {
              "identifiers": [
                "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest"
              ],
              "kind": "relationships",
              "title": "Inherits From",
              "type": "inheritsFrom"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/seeAlsoSections",
          "value": [
            {
              "anchor": "Machine-learning-image-analysis",
              "generated": true,
              "identifiers": [
                "doc://com.apple.documentation/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml",
                "doc://com.apple.vision/documentation/Vision/training-a-create-ml-model-to-classify-flowers",
                "doc://com.apple.vision/documentation/Vision/VNClassificationObservation",
                "doc://com.apple.vision/documentation/Vision/VNPixelBufferObservation",
                "doc://com.apple.vision/documentation/Vision/VNCoreMLFeatureValueObservation"
              ],
              "title": "Machine learning image analysis"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/primaryContentSections/0",
          "value": {
            "declarations": [
              {
                "languages": [
                  "occ"
                ],
                "platforms": [
                  "iOS",
                  "iPadOS",
                  "Mac Catalyst",
                  "macOS",
                  "tvOS",
                  "visionOS"
                ],
                "tokens": [
                  {
                    "kind": "keyword",
                    "text": "@interface"
                  },
                  {
                    "kind": "text",
                    "text": " "
                  },
                  {
                    "kind": "identifier",
                    "text": "VNCoreMLRequest"
                  },
                  {
                    "kind": "text",
                    "text": " : "
                  },
                  {
                    "identifier": "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest",
                    "kind": "typeIdentifier",
                    "preciseIdentifier": "c:objc(cs)VNImageBasedRequest",
                    "text": "VNImageBasedRequest"
                  }
                ]
              }
            ],
            "kind": "declarations"
          }
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1imageCropAndScaleOption/title",
          "value": "imageCropAndScaleOption"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1imageCropAndScaleOption/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "imageCropAndScaleOption"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequestRevision1/title",
          "value": "VNCoreMLRequestRevision1"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequestRevision1/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLRequestRevision1"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNClassificationObservation/title",
          "value": "VNClassificationObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNClassificationObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNClassificationObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNClassificationObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNClassificationObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNObservation~1confidence/title",
          "value": "confidence"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNObservation~1confidence/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "confidence"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1CoreML~1MLModel~1modelDescription/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@property"
            },
            {
              "kind": "text",
              "text": " ("
            },
            {
              "kind": "keyword",
              "text": "nonatomic"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "kind": "keyword",
              "text": "readonly"
            },
            {
              "kind": "text",
              "text": ") "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)MLModelDescription",
              "text": "MLModelDescription"
            },
            {
              "kind": "text",
              "text": " * "
            },
            {
              "kind": "identifier",
              "text": "modelDescription"
            },
            {
              "kind": "text",
              "text": ";"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.externally.resolved.symbol~1c:objc(pl)NSObject/title",
          "value": "NSObject"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageBasedRequest/title",
          "value": "VNImageBasedRequest"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageBasedRequest/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageBasedRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageBasedRequest/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageBasedRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageCropAndScaleOption/title",
          "value": "VNImageCropAndScaleOption"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageCropAndScaleOption/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageCropAndScaleOption"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageCropAndScaleOption/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageCropAndScaleOption"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLModel/title",
          "value": "VNCoreMLModel"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLModel/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLModel"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLModel/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLModel"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1init(model:)/title",
          "value": "initWithModel:"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1init(model:)/fragments",
          "value": [
            {
              "kind": "text",
              "text": "- "
            },
            {
              "kind": "identifier",
              "text": "initWithModel:"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLFeatureValueObservation/title",
          "value": "VNCoreMLFeatureValueObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLFeatureValueObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLFeatureValueObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLFeatureValueObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLFeatureValueObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1model/title",
          "value": "model"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1model/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "model"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1init(model:completionHandler:)/title",
          "value": "initWithModel:completionHandler:"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest~1init(model:completionHandler:)/fragments",
          "value": [
            {
              "kind": "text",
              "text": "- "
            },
            {
              "kind": "identifier",
              "text": "initWithModel:completionHandler:"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1CoreML~1MLFeatureType~1image/title",
          "value": "MLFeatureTypeImage"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1CoreML~1MLFeatureType~1image/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "MLFeatureTypeImage"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPixelBufferObservation/title",
          "value": "VNPixelBufferObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPixelBufferObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNPixelBufferObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPixelBufferObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNPixelBufferObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1CoreML~1MLModelDescription~1predictedFeatureName/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@property"
            },
            {
              "kind": "text",
              "text": " ("
            },
            {
              "kind": "keyword",
              "text": "nonatomic"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "kind": "keyword",
              "text": "copy"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "kind": "keyword",
              "text": "readonly"
            },
            {
              "kind": "text",
              "text": ") "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)NSString",
              "text": "NSString"
            },
            {
              "kind": "text",
              "text": " * "
            },
            {
              "kind": "identifier",
              "text": "predictedFeatureName"
            },
            {
              "kind": "text",
              "text": ";"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest/title",
          "value": "VNCoreMLRequest"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNCoreMLRequest/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNCoreMLRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1CoreML~1MLModel/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@interface"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "MLModel"
            },
            {
              "kind": "text",
              "text": " : "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)NSObject",
              "text": "NSObject"
            }
          ]
        }
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/vncoremlrequest"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    },
    {
      "paths": [
        "/documentation/vision/vncoremlrequest"
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ]
}
