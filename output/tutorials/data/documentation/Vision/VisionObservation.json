{
  "abstract": [
    {
      "text": "A type for objects produced by image-analysis requests.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/VisionObservation"
  },
  "kind": "symbol",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "externalID": "s:6Vision0A11ObservationP",
    "fragments": [
      {
        "kind": "keyword",
        "text": "protocol"
      },
      {
        "kind": "text",
        "text": " "
      },
      {
        "kind": "identifier",
        "text": "VisionObservation"
      }
    ],
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "navigatorTitle": [
      {
        "kind": "identifier",
        "text": "VisionObservation"
      }
    ],
    "platforms": [
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "iPadOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "Mac Catalyst",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "15.0",
        "name": "macOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "18.0",
        "name": "tvOS",
        "unavailable": false
      },
      {
        "beta": false,
        "deprecated": false,
        "introducedAt": "2.0",
        "name": "visionOS",
        "unavailable": false
      }
    ],
    "role": "symbol",
    "roleHeading": "Protocol",
    "symbolKind": "protocol",
    "title": "VisionObservation"
  },
  "primaryContentSections": [
    {
      "declarations": [
        {
          "languages": [
            "swift"
          ],
          "platforms": [
            "iOS",
            "iPadOS",
            "Mac Catalyst",
            "macOS",
            "tvOS",
            "visionOS"
          ],
          "tokens": [
            {
              "kind": "keyword",
              "text": "protocol"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "VisionObservation"
            },
            {
              "kind": "text",
              "text": " : "
            },
            {
              "identifier": "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
              "kind": "typeIdentifier",
              "preciseIdentifier": "s:s23CustomStringConvertibleP",
              "text": "CustomStringConvertible"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "identifier": "doc://com.externally.resolved.symbol/s:Se",
              "kind": "typeIdentifier",
              "preciseIdentifier": "s:Se",
              "text": "Decodable"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "identifier": "doc://com.externally.resolved.symbol/s:SE",
              "kind": "typeIdentifier",
              "preciseIdentifier": "s:SE",
              "text": "Encodable"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "identifier": "doc://com.externally.resolved.symbol/s:SH",
              "kind": "typeIdentifier",
              "preciseIdentifier": "s:SH",
              "text": "Hashable"
            },
            {
              "kind": "text",
              "text": ", "
            },
            {
              "identifier": "doc://com.externally.resolved.symbol/s:s8SendableP",
              "kind": "typeIdentifier",
              "preciseIdentifier": "s:s8SendableP",
              "text": "Sendable"
            }
          ]
        }
      ],
      "kind": "declarations"
    }
  ],
  "references": {
    "classifying-images-for-categorization-and-search-PageImage-card.png": {
      "alt": "[An illustration depicting the selection of one image out of multiple images.]",
      "identifier": "classifying-images-for-categorization-and-search-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/4eabbb99abb5c902d499f93f57a9cf22/classifying-images-for-categorization-and-search-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/477f01072bf9eb417cbb5cf846e38226/classifying-images-for-categorization-and-search-PageImage-card~dark@2x.png"
        }
      ]
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/AnimalBodyPoseObservation": {
      "abstract": [
        {
          "text": "An observation that provides the animal body points the analysis recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "AnimalBodyPoseObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/AnimalBodyPoseObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "AnimalBodyPoseObservation"
        }
      ],
      "role": "symbol",
      "title": "AnimalBodyPoseObservation",
      "type": "topic",
      "url": "/documentation/vision/animalbodyposeobservation"
    },
    "doc://com.apple.vision/documentation/Vision/BarcodeObservation": {
      "abstract": [
        {
          "text": "An object that represents barcode information that an image-analysis request detects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "BarcodeObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/BarcodeObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "BarcodeObservation"
        }
      ],
      "role": "symbol",
      "title": "BarcodeObservation",
      "type": "topic",
      "url": "/documentation/vision/barcodeobservation"
    },
    "doc://com.apple.vision/documentation/Vision/ClassificationObservation": {
      "abstract": [
        {
          "text": "An object that represents classification information that an image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ClassificationObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ClassificationObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ClassificationObservation"
        }
      ],
      "role": "symbol",
      "title": "ClassificationObservation",
      "type": "topic",
      "url": "/documentation/vision/classificationobservation"
    },
    "doc://com.apple.vision/documentation/Vision/ClassifyImageRequest": {
      "abstract": [
        {
          "text": "A request to classify an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ClassifyImageRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ClassifyImageRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ClassifyImageRequest"
        }
      ],
      "role": "symbol",
      "title": "ClassifyImageRequest",
      "type": "topic",
      "url": "/documentation/vision/classifyimagerequest"
    },
    "doc://com.apple.vision/documentation/Vision/ContoursObservation": {
      "abstract": [
        {
          "text": "An object that represents the detected contours in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ContoursObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ContoursObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ContoursObservation"
        }
      ],
      "role": "symbol",
      "title": "ContoursObservation",
      "type": "topic",
      "url": "/documentation/vision/contoursobservation"
    },
    "doc://com.apple.vision/documentation/Vision/CoreMLFeatureValueObservation": {
      "abstract": [
        {
          "text": "An object that represents a collection of key-value information that a Core ML image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CoreMLFeatureValueObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/CoreMLFeatureValueObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "CoreMLFeatureValueObservation"
        }
      ],
      "role": "symbol",
      "title": "CoreMLFeatureValueObservation",
      "type": "topic",
      "url": "/documentation/vision/coremlfeaturevalueobservation"
    },
    "doc://com.apple.vision/documentation/Vision/DetectedDocumentObservation": {
      "abstract": [
        {
          "text": "The heat map that’s a pixel buffer in a one-component floating-point pixel format.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "DetectedDocumentObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectedDocumentObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "DetectedDocumentObservation"
        }
      ],
      "role": "symbol",
      "title": "DetectedDocumentObservation",
      "type": "topic",
      "url": "/documentation/vision/detecteddocumentobservation"
    },
    "doc://com.apple.vision/documentation/Vision/DetectedObjectObservation": {
      "abstract": [
        {
          "text": "An observation that provides the position and extent of an image feature that an image-analysis request detects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "DetectedObjectObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/DetectedObjectObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "DetectedObjectObservation"
        }
      ],
      "role": "symbol",
      "title": "DetectedObjectObservation",
      "type": "topic",
      "url": "/documentation/vision/detectedobjectobservation"
    },
    "doc://com.apple.vision/documentation/Vision/FaceObservation": {
      "abstract": [
        {
          "text": "An image-analysis request that identifies facial features in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "FaceObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/FaceObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "FaceObservation"
        }
      ],
      "role": "symbol",
      "title": "FaceObservation",
      "type": "topic",
      "url": "/documentation/vision/faceobservation"
    },
    "doc://com.apple.vision/documentation/Vision/FeaturePrintObservation": {
      "abstract": [
        {
          "text": "An observation that provides the recognized feature print.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "FeaturePrintObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/FeaturePrintObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "FeaturePrintObservation"
        }
      ],
      "role": "symbol",
      "title": "FeaturePrintObservation",
      "type": "topic",
      "url": "/documentation/vision/featureprintobservation"
    },
    "doc://com.apple.vision/documentation/Vision/HorizonObservation": {
      "abstract": [
        {
          "text": "The horizon angle information that an image-analysis request detects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "HorizonObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/HorizonObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "HorizonObservation"
        }
      ],
      "role": "symbol",
      "title": "HorizonObservation",
      "type": "topic",
      "url": "/documentation/vision/horizonobservation"
    },
    "doc://com.apple.vision/documentation/Vision/HumanBodyPose3DObservation": {
      "abstract": [
        {
          "text": "An observation that provides the 3D body points the request recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "HumanBodyPose3DObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/HumanBodyPose3DObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "HumanBodyPose3DObservation"
        }
      ],
      "role": "symbol",
      "title": "HumanBodyPose3DObservation",
      "type": "topic",
      "url": "/documentation/vision/humanbodypose3dobservation"
    },
    "doc://com.apple.vision/documentation/Vision/HumanBodyPoseObservation": {
      "abstract": [
        {
          "text": "An observation that provides the body points the analysis recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "HumanBodyPoseObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/HumanBodyPoseObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "HumanBodyPoseObservation"
        }
      ],
      "role": "symbol",
      "title": "HumanBodyPoseObservation",
      "type": "topic",
      "url": "/documentation/vision/humanbodyposeobservation"
    },
    "doc://com.apple.vision/documentation/Vision/HumanHandPoseObservation": {
      "abstract": [
        {
          "text": "An observation that provides the hand points the analysis recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "HumanHandPoseObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/HumanHandPoseObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "HumanHandPoseObservation"
        }
      ],
      "role": "symbol",
      "title": "HumanHandPoseObservation",
      "type": "topic",
      "url": "/documentation/vision/humanhandposeobservation"
    },
    "doc://com.apple.vision/documentation/Vision/HumanObservation": {
      "abstract": [
        {
          "text": "An object that represents a person that the request detects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "HumanObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/HumanObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "HumanObservation"
        }
      ],
      "role": "symbol",
      "title": "HumanObservation",
      "type": "topic",
      "url": "/documentation/vision/humanobservation"
    },
    "doc://com.apple.vision/documentation/Vision/ImageAestheticsScoresObservation": {
      "abstract": [
        {
          "text": "An observation that provides an overall score of aesthetic attributes for an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAestheticsScoresObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageAestheticsScoresObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAestheticsScoresObservation"
        }
      ],
      "role": "symbol",
      "title": "ImageAestheticsScoresObservation",
      "type": "topic",
      "url": "/documentation/vision/imageaestheticsscoresobservation"
    },
    "doc://com.apple.vision/documentation/Vision/ImageHomographicAlignmentObservation": {
      "abstract": [
        {
          "text": "An object that represents a perspective warp transformation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageHomographicAlignmentObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageHomographicAlignmentObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageHomographicAlignmentObservation"
        }
      ],
      "role": "symbol",
      "title": "ImageHomographicAlignmentObservation",
      "type": "topic",
      "url": "/documentation/vision/imagehomographicalignmentobservation"
    },
    "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest": {
      "abstract": [
        {
          "text": "A type for image-analysis requests that focus on a specific part of an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageProcessingRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageProcessingRequest"
        }
      ],
      "role": "symbol",
      "title": "ImageProcessingRequest",
      "type": "topic",
      "url": "/documentation/vision/imageprocessingrequest"
    },
    "doc://com.apple.vision/documentation/Vision/ImageRequestHandler": {
      "abstract": [
        {
          "text": "An object that processes one or more image-analysis requests pertaining to a single image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageRequestHandler"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageRequestHandler",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageRequestHandler"
        }
      ],
      "role": "symbol",
      "title": "ImageRequestHandler",
      "type": "topic",
      "url": "/documentation/vision/imagerequesthandler"
    },
    "doc://com.apple.vision/documentation/Vision/ImageTranslationAlignmentObservation": {
      "abstract": [
        {
          "text": "Affine transform information that an image-alignment request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageTranslationAlignmentObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/ImageTranslationAlignmentObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageTranslationAlignmentObservation"
        }
      ],
      "role": "symbol",
      "title": "ImageTranslationAlignmentObservation",
      "type": "topic",
      "url": "/documentation/vision/imagetranslationalignmentobservation"
    },
    "doc://com.apple.vision/documentation/Vision/InstanceMaskObservation": {
      "abstract": [
        {
          "text": "An observation that contains an instance mask that labels instances in the mask.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "InstanceMaskObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/InstanceMaskObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "InstanceMaskObservation"
        }
      ],
      "role": "symbol",
      "title": "InstanceMaskObservation",
      "type": "topic",
      "url": "/documentation/vision/instancemaskobservation"
    },
    "doc://com.apple.vision/documentation/Vision/OpticalFlowObservation": {
      "abstract": [
        {
          "text": "An object that represents an optical flow that an image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "OpticalFlowObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/OpticalFlowObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "OpticalFlowObservation"
        }
      ],
      "role": "symbol",
      "title": "OpticalFlowObservation",
      "type": "topic",
      "url": "/documentation/vision/opticalflowobservation"
    },
    "doc://com.apple.vision/documentation/Vision/PixelBufferObservation": {
      "abstract": [
        {
          "text": "An object that represents an image that an image-analysis request produces.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "PixelBufferObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/PixelBufferObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "PixelBufferObservation"
        }
      ],
      "role": "symbol",
      "title": "PixelBufferObservation",
      "type": "topic",
      "url": "/documentation/vision/pixelbufferobservation"
    },
    "doc://com.apple.vision/documentation/Vision/RecognizedObjectObservation": {
      "abstract": [
        {
          "text": "An observation with an array of classification labels that classify the recognized object.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "RecognizedObjectObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/RecognizedObjectObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "RecognizedObjectObservation"
        }
      ],
      "role": "symbol",
      "title": "RecognizedObjectObservation",
      "type": "topic",
      "url": "/documentation/vision/recognizedobjectobservation"
    },
    "doc://com.apple.vision/documentation/Vision/RecognizedTextObservation": {
      "abstract": [
        {
          "text": "An object that contains information about both the location and content of text and glyphs that the framework recognizes in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "RecognizedTextObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/RecognizedTextObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "RecognizedTextObservation"
        }
      ],
      "role": "symbol",
      "title": "RecognizedTextObservation",
      "type": "topic",
      "url": "/documentation/vision/recognizedtextobservation"
    },
    "doc://com.apple.vision/documentation/Vision/RectangleObservation": {
      "abstract": [
        {
          "text": "An object that represents the four vertices of a detected rectangle.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "RectangleObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/RectangleObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "RectangleObservation"
        }
      ],
      "role": "symbol",
      "title": "RectangleObservation",
      "type": "topic",
      "url": "/documentation/vision/rectangleobservation"
    },
    "doc://com.apple.vision/documentation/Vision/RequestDescriptor": {
      "abstract": [
        {
          "text": "A type that describes the request and revision combination.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "enum"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "RequestDescriptor"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/RequestDescriptor",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "RequestDescriptor"
        }
      ],
      "role": "symbol",
      "title": "RequestDescriptor",
      "type": "topic",
      "url": "/documentation/vision/requestdescriptor"
    },
    "doc://com.apple.vision/documentation/Vision/SaliencyImageObservation": {
      "abstract": [
        {
          "text": "An observation that contains a grayscale heat map of important areas across an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "SaliencyImageObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/SaliencyImageObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "SaliencyImageObservation"
        }
      ],
      "role": "symbol",
      "title": "SaliencyImageObservation",
      "type": "topic",
      "url": "/documentation/vision/saliencyimageobservation"
    },
    "doc://com.apple.vision/documentation/Vision/TextObservation": {
      "abstract": [
        {
          "text": "Information about regions of text that an image-analysis request detects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "TextObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/TextObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "TextObservation"
        }
      ],
      "role": "symbol",
      "title": "TextObservation",
      "type": "topic",
      "url": "/documentation/vision/textobservation"
    },
    "doc://com.apple.vision/documentation/Vision/TrajectoryObservation": {
      "abstract": [
        {
          "text": "An observation that describes a detected trajectory.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "TrajectoryObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/TrajectoryObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "TrajectoryObservation"
        }
      ],
      "role": "symbol",
      "title": "TrajectoryObservation",
      "type": "topic",
      "url": "/documentation/vision/trajectoryobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation": {
      "abstract": [
        {
          "text": "A type for objects produced by image-analysis requests.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VisionObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VisionObservation"
        }
      ],
      "role": "symbol",
      "title": "VisionObservation",
      "type": "topic",
      "url": "/documentation/vision/visionobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/Hashable-Implementations": {
      "abstract": [],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/Hashable-Implementations",
      "kind": "article",
      "role": "collectionGroup",
      "title": "Hashable Implementations",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/hashable-implementations"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/confidence": {
      "abstract": [
        {
          "text": "The level of confidence in the observation’s accuracy.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "confidence"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Sf",
          "text": "Float"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/confidence",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "confidence",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/confidence"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/description": {
      "abstract": [
        {
          "text": "A textual representation of this instance.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "description"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/description",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "description",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/description"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/hash(into:)": {
      "abstract": [
        {
          "text": "Hashes the essential components of the value by passing them into the hasher.",
          "type": "text"
        }
      ],
      "defaultImplementations": 1,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "hash"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "into"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "keyword",
          "text": "inout"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:s6HasherV",
          "text": "Hasher"
        },
        {
          "kind": "text",
          "text": ")"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/hash(into:)",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "hash(into:)",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/hash(into:)"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/originatingRequestDescriptor": {
      "abstract": [
        {
          "text": "The descriptor of the request that produces the observation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "originatingRequestDescriptor"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:6Vision17RequestDescriptorO",
          "text": "RequestDescriptor"
        },
        {
          "kind": "text",
          "text": "?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/originatingRequestDescriptor",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "originatingRequestDescriptor",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/originatingrequestdescriptor"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/timeRange": {
      "abstract": [
        {
          "text": "The time range of the reported observation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "timeRange"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@SA@CMTimeRange",
          "text": "CMTimeRange"
        },
        {
          "kind": "text",
          "text": "?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/timeRange",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "timeRange",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/timerange"
    },
    "doc://com.apple.vision/documentation/Vision/VisionObservation/uuid": {
      "abstract": [
        {
          "text": "A unique alphanumeric value that the framework assigns the observation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "uuid"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:10Foundation4UUIDV",
          "text": "UUID"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionObservation/uuid",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "uuid",
      "type": "topic",
      "url": "/documentation/vision/visionobservation/uuid"
    },
    "doc://com.apple.vision/documentation/Vision/VisionRequest": {
      "abstract": [
        {
          "text": "A type for image-analysis requests.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VisionRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VisionRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VisionRequest"
        }
      ],
      "role": "symbol",
      "title": "VisionRequest",
      "type": "topic",
      "url": "/documentation/vision/visionrequest"
    },
    "doc://com.apple.vision/documentation/Vision/classifying-images-for-categorization-and-search": {
      "abstract": [
        {
          "text": "Analyze and label images using a Vision classification request.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/classifying-images-for-categorization-and-search",
      "images": [
        {
          "identifier": "classifying-images-for-categorization-and-search-PageImage-card.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "sampleCode",
      "title": "Classifying images for categorization and search",
      "type": "topic",
      "url": "/documentation/vision/classifying-images-for-categorization-and-search"
    },
    "doc://com.externally.resolved.symbol/s:SE": {
      "abstract": [
        {
          "text": "A type that can encode itself to an external representation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Encodable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SE",
      "kind": "symbol",
      "role": "symbol",
      "title": "Encodable",
      "type": "topic",
      "url": "/documentation/Swift/Encodable"
    },
    "doc://com.externally.resolved.symbol/s:SH": {
      "abstract": [
        {
          "text": "A type that can be hashed into a `Hasher` to produce an integer hash value.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Hashable"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SQ",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SH",
      "kind": "symbol",
      "role": "symbol",
      "title": "Hashable",
      "type": "topic",
      "url": "/documentation/Swift/Hashable"
    },
    "doc://com.externally.resolved.symbol/s:SQ": {
      "abstract": [
        {
          "text": "A type that can be compared for value equality.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Equatable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:SQ",
      "kind": "symbol",
      "role": "symbol",
      "title": "Equatable",
      "type": "topic",
      "url": "/documentation/Swift/Equatable"
    },
    "doc://com.externally.resolved.symbol/s:Se": {
      "abstract": [
        {
          "text": "A type that can decode itself from an external representation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Decodable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:Se",
      "kind": "symbol",
      "role": "symbol",
      "title": "Decodable",
      "type": "topic",
      "url": "/documentation/Swift/Decodable"
    },
    "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP": {
      "abstract": [
        {
          "text": "A type with a customized textual representation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "CustomStringConvertible"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
      "kind": "symbol",
      "role": "symbol",
      "title": "CustomStringConvertible",
      "type": "topic",
      "url": "/documentation/Swift/CustomStringConvertible"
    },
    "doc://com.externally.resolved.symbol/s:s8SendableP": {
      "abstract": [
        {
          "text": "A thread-safe type whose values can be shared across arbitrary concurrent contexts without introducing a risk of data races.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Sendable"
        }
      ],
      "identifier": "doc://com.externally.resolved.symbol/s:s8SendableP",
      "kind": "symbol",
      "role": "symbol",
      "title": "Sendable",
      "type": "topic",
      "url": "/documentation/Swift/Sendable"
    }
  },
  "relationshipsSections": [
    {
      "identifiers": [
        "doc://com.externally.resolved.symbol/s:s23CustomStringConvertibleP",
        "doc://com.externally.resolved.symbol/s:Se",
        "doc://com.externally.resolved.symbol/s:SE",
        "doc://com.externally.resolved.symbol/s:SQ",
        "doc://com.externally.resolved.symbol/s:SH",
        "doc://com.externally.resolved.symbol/s:s8SendableP"
      ],
      "kind": "relationships",
      "title": "Inherits From",
      "type": "inheritsFrom"
    },
    {
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/AnimalBodyPoseObservation",
        "doc://com.apple.vision/documentation/Vision/BarcodeObservation",
        "doc://com.apple.vision/documentation/Vision/ClassificationObservation",
        "doc://com.apple.vision/documentation/Vision/ContoursObservation",
        "doc://com.apple.vision/documentation/Vision/CoreMLFeatureValueObservation",
        "doc://com.apple.vision/documentation/Vision/DetectedDocumentObservation",
        "doc://com.apple.vision/documentation/Vision/DetectedObjectObservation",
        "doc://com.apple.vision/documentation/Vision/FaceObservation",
        "doc://com.apple.vision/documentation/Vision/FeaturePrintObservation",
        "doc://com.apple.vision/documentation/Vision/HorizonObservation",
        "doc://com.apple.vision/documentation/Vision/HumanBodyPose3DObservation",
        "doc://com.apple.vision/documentation/Vision/HumanBodyPoseObservation",
        "doc://com.apple.vision/documentation/Vision/HumanHandPoseObservation",
        "doc://com.apple.vision/documentation/Vision/HumanObservation",
        "doc://com.apple.vision/documentation/Vision/ImageAestheticsScoresObservation",
        "doc://com.apple.vision/documentation/Vision/ImageHomographicAlignmentObservation",
        "doc://com.apple.vision/documentation/Vision/ImageTranslationAlignmentObservation",
        "doc://com.apple.vision/documentation/Vision/InstanceMaskObservation",
        "doc://com.apple.vision/documentation/Vision/OpticalFlowObservation",
        "doc://com.apple.vision/documentation/Vision/PixelBufferObservation",
        "doc://com.apple.vision/documentation/Vision/RecognizedObjectObservation",
        "doc://com.apple.vision/documentation/Vision/RecognizedTextObservation",
        "doc://com.apple.vision/documentation/Vision/RectangleObservation",
        "doc://com.apple.vision/documentation/Vision/SaliencyImageObservation",
        "doc://com.apple.vision/documentation/Vision/TextObservation",
        "doc://com.apple.vision/documentation/Vision/TrajectoryObservation"
      ],
      "kind": "relationships",
      "title": "Conforming Types",
      "type": "conformingTypes"
    }
  ],
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Still-image-analysis",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/classifying-images-for-categorization-and-search",
        "doc://com.apple.vision/documentation/Vision/ClassifyImageRequest",
        "doc://com.apple.vision/documentation/Vision/ImageProcessingRequest",
        "doc://com.apple.vision/documentation/Vision/ImageRequestHandler",
        "doc://com.apple.vision/documentation/Vision/VisionRequest"
      ],
      "title": "Still-image analysis"
    }
  ],
  "topicSections": [
    {
      "anchor": "Inspecting-an-observation",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VisionObservation/uuid",
        "doc://com.apple.vision/documentation/Vision/VisionObservation/confidence",
        "doc://com.apple.vision/documentation/Vision/VisionObservation/description",
        "doc://com.apple.vision/documentation/Vision/VisionObservation/originatingRequestDescriptor",
        "doc://com.apple.vision/documentation/Vision/RequestDescriptor",
        "doc://com.apple.vision/documentation/Vision/VisionObservation/timeRange"
      ],
      "title": "Inspecting an observation"
    },
    {
      "anchor": "Hashing-the-observation",
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VisionObservation/hash(into:)"
      ],
      "title": "Hashing the observation"
    },
    {
      "anchor": "Default-Implementations",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/VisionObservation/Hashable-Implementations"
      ],
      "title": "Default Implementations"
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/visionobservation"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    }
  ]
}
