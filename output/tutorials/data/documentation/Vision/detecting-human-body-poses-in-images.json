{
  "abstract": [
    {
      "text": "Add the capability to detect human body poses to your app using the Vision framework.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision",
        "doc://com.apple.vision/documentation/Vision/original-objective-c-and-swift-api"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-images"
  },
  "kind": "article",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "role": "article",
    "roleHeading": "Article",
    "title": "Detecting Human Body Poses in Images"
  },
  "primaryContentSections": [
    {
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "A primary goal of Vision is to provide you with tools to help you better identify and understand people in your visual data. Starting in iOS 14 and macOS 11, Vision adds the powerful new ability to identify human body poses. It does so by detecting up to 19 unique body points, as shown in the figure below.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "identifier": "media-3625688",
              "type": "image"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "You can use Vision’s capability for detecting human body poses on its own or with Core ML. Combining Vision with the power of machine learning enables a wide variety of feature possibilities. For example, a safety-training app could help employees use correct ergonomics, a fitness app could automatically track the exercise a user performs, and a media-editing app could find photos or videos based on pose similarity.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Perform-a-Body-Pose-Request",
          "level": 3,
          "text": "Perform a Body Pose Request",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Vision provides its body pose-detection capabilities through ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPoseRequest",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ", an image-based request type that detects key body points. The following example shows how to use ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNImageRequestHandler",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " to perform a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPoseRequest",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " for detecting body points in the specified ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/coregraphics/cgimage",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "// Get the CGImage on which to perform requests.",
            "guard let cgImage = UIImage(named: \"bodypose\")?.cgImage else { return }",
            "",
            "// Create a new image-request handler.",
            "let requestHandler = VNImageRequestHandler(cgImage: cgImage)",
            "",
            "// Create a new request to recognize a human body pose.",
            "let request = VNDetectHumanBodyPoseRequest(completionHandler: bodyPoseHandler)",
            "",
            "do {",
            "    // Perform the body pose-detection request.",
            "    try requestHandler.perform([request])",
            "} catch {",
            "    print(\"Unable to perform the request: \\(error).\")",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "",
                  "type": "text"
                },
                {
                  "text": " ",
                  "type": "text"
                },
                {
                  "text": "If you have a known region of interest (ROI) in an image, you can specify it using the request’s ",
                  "type": "text"
                },
                {
                  "identifier": "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest/regionOfInterest",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": " property. Setting an ROI reduces the region in the image where the request performs its analysis, which generally results in more accurate pose estimation.",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        },
        {
          "anchor": "Process-the-Results",
          "level": 3,
          "text": "Process the Results",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "After the request handler processes the request, it calls the request’s completion closure, passing it the request and any errors that occurred. Retrieve the observations by querying the request object for its ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNRequest/results",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ", which it returns as an array of ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " objects. The request returns a unique observation for each detected human body pose, with each containing the recognized points and a confidence score indicating the accuracy of the observation.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "func bodyPoseHandler(request: VNRequest, error: Error?) {",
            "    guard let observations =",
            "            request.results as? [VNHumanBodyPoseObservation] else { ",
            "        return ",
            "    }",
            "    ",
            "    // Process each observation to find the recognized body pose points.",
            "    observations.forEach { processObservation($0) }",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "anchor": "Retrieve-the-Points",
          "level": 3,
          "text": "Retrieve the Points",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Retrieve the points of interest from the observation by calling its ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/recognizedPoints(_:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " method. The argument you pass to this method is a key that identifies all of the points for a particular body region (see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/JointsGroupName",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " for supported values). This method returns the recognized points for the region as a dictionary of ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " objects keyed by joint name. Each instance of ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " provides the ",
              "type": "text"
            },
            {
              "code": "X",
              "type": "codeVoice"
            },
            {
              "text": " and ",
              "type": "text"
            },
            {
              "code": "Y",
              "type": "codeVoice"
            },
            {
              "text": " coordinates, in normalized space, and a confidence score for the point. Ignore any recognized points with a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectedPoint/confidence",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " value of 0, because they’re invalid.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The following code example retrieves all of the recognized points for the torso and maps them to an array of ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/corefoundation/cgpoint",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " objects. The example first retrieves the recognized points of the torso by calling ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/recognizedPoints(_:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": "with the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/JointsGroupName/torso",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " key. It then iterates over the specific point keys of the torso and retrieves their associated ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object. Finally, if a point’s ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectedPoint/confidence",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " score is greater than 0, it extracts the point’s coordinates as a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/corefoundation/cgpoint",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "func processObservation(_ observation: VNHumanBodyPoseObservation) {",
            "    ",
            "    // Retrieve all torso points.",
            "    guard let recognizedPoints =",
            "            try? observation.recognizedPoints(.torso) else { return }",
            "    ",
            "    // Torso joint names in a clockwise ordering.",
            "    let torsoJointNames: [VNHumanBodyPoseObservation.JointName] = [",
            "        .neck,",
            "        .rightShoulder,",
            "        .rightHip,",
            "        .root,",
            "        .leftHip,",
            "        .leftShoulder",
            "    ]",
            "    ",
            "    // Retrieve the CGPoints containing the normalized X and Y coordinates.",
            "    let imagePoints: [CGPoint] = torsoJointNames.compactMap {",
            "        guard let point = recognizedPoints[$0], point.confidence > 0 else { return nil }",
            "        ",
            "        // Translate the point from normalized-coordinates to image coordinates.",
            "        return VNImagePointForNormalizedPoint(point.location,",
            "                                              Int(imageSize.width),",
            "                                              Int(imageSize.height))",
            "    }",
            "    ",
            "    // Draw the points onscreen.",
            "    draw(points: imagePoints)",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "",
                  "type": "text"
                },
                {
                  "text": " ",
                  "type": "text"
                },
                {
                  "text": "The points the ",
                  "type": "text"
                },
                {
                  "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/recognizedPoints(_:)",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": " method returns are in normalized coordinates (0.0 to 1.0), with the origin at the bottom-left. Use the ",
                  "type": "text"
                },
                {
                  "identifier": "doc://com.apple.vision/documentation/Vision/VNImagePointForNormalizedPoint(_:_:_:)",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": " function to translate the normalized points to the input image coordinates.",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        },
        {
          "inlineContent": [
            {
              "text": "For an example of how you can use and visualize recognized body points, see the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/building-a-feature-rich-app-for-sports-analysis",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " sample app.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Improve-Pose-Detection-Accuracy",
          "level": 3,
          "text": "Improve Pose-Detection Accuracy",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "To achieve the most accurate results from Vision’s human body pose-detection capabilities, consider the following points:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "items": [
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "The subject’s height should ideally be at least a third of the overall image height.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "A large portion of the subject’s key body regions and points should be present in the image.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "A subject wearing flowing or robe-like clothing reduces the detection accuracy.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Attempting to detect body poses in dense crowd scenes is likely to produce inaccurate results.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            }
          ],
          "type": "unorderedList"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/corefoundation/cgpoint": {
      "abstract": [
        {
          "text": "A structure that contains a point in a two-dimensional coordinate system.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "text",
          "text": "struct "
        },
        {
          "kind": "identifier",
          "text": "CGPoint"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/corefoundation/cgpoint",
      "kind": "symbol",
      "role": "symbol",
      "title": "CGPoint",
      "type": "topic",
      "url": "/documentation/corefoundation/cgpoint"
    },
    "doc://com.apple.documentation/documentation/coregraphics/cgimage": {
      "abstract": [
        {
          "text": "A bitmap image or image mask.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "text",
          "text": "class "
        },
        {
          "kind": "identifier",
          "text": "CGImage"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/coregraphics/cgimage",
      "kind": "symbol",
      "role": "symbol",
      "title": "CGImage",
      "type": "topic",
      "url": "/documentation/coregraphics/cgimage"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPoseRequest": {
      "abstract": [
        {
          "text": "A request that detects a human body pose.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNDetectHumanBodyPoseRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPoseRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNDetectHumanBodyPoseRequest"
        }
      ],
      "role": "symbol",
      "title": "VNDetectHumanBodyPoseRequest",
      "type": "topic",
      "url": "/documentation/vision/vndetecthumanbodyposerequest"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectHumanHandPoseRequest": {
      "abstract": [
        {
          "text": "A request that detects a human hand pose.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNDetectHumanHandPoseRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanHandPoseRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNDetectHumanHandPoseRequest"
        }
      ],
      "role": "symbol",
      "title": "VNDetectHumanHandPoseRequest",
      "type": "topic",
      "url": "/documentation/vision/vndetecthumanhandposerequest"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectedPoint": {
      "abstract": [
        {
          "text": "An object that represents a normalized point in an image, along with a confidence value.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNDetectedPoint"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectedPoint",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNDetectedPoint"
        }
      ],
      "role": "symbol",
      "title": "VNDetectedPoint",
      "type": "topic",
      "url": "/documentation/vision/vndetectedpoint"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectedPoint/confidence": {
      "abstract": [
        {
          "text": "A confidence score that indicates the detected point’s accuracy.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "confidence"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNConfidence",
          "text": "VNConfidence"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectedPoint/confidence",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "confidence"
        }
      ],
      "role": "symbol",
      "title": "confidence",
      "type": "topic",
      "url": "/documentation/vision/vndetectedpoint/confidence"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation": {
      "abstract": [
        {
          "text": "An observation that provides the body points the analysis recognized.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNHumanBodyPoseObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanBodyPoseObservation"
        }
      ],
      "role": "symbol",
      "title": "VNHumanBodyPoseObservation",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyposeobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/JointsGroupName": {
      "abstract": [
        {
          "text": "The supported joint group names for the body pose.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "JointsGroupName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/JointsGroupName",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "JointsGroupName"
        }
      ],
      "role": "symbol",
      "title": "VNHumanBodyPoseObservation.JointsGroupName",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyposeobservation/jointsgroupname"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/JointsGroupName/torso": {
      "abstract": [
        {
          "text": "The torso.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "torso"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPoseObservation",
          "text": "VNHumanBodyPoseObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPoseObservationJointsGroupName",
          "text": "JointsGroupName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/JointsGroupName/torso",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanBodyPoseObservationJointsGroupNameTorso"
        }
      ],
      "role": "symbol",
      "title": "torso",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyposeobservation/jointsgroupname/torso"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/recognizedPoints(_:)": {
      "abstract": [
        {
          "text": "Retrieves the recognized points associated with the joint group name.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "recognizedPoints"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPoseObservation",
          "text": "VNHumanBodyPoseObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPoseObservationJointsGroupName",
          "text": "JointsGroupName"
        },
        {
          "kind": "text",
          "text": ") "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPoseObservation",
          "text": "VNHumanBodyPoseObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPoseObservationJointName",
          "text": "JointName"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNRecognizedPoint",
          "text": "VNRecognizedPoint"
        },
        {
          "kind": "text",
          "text": "]"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation/recognizedPoints(_:)",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "recognizedPointsForJointsGroupName:error:"
        }
      ],
      "role": "symbol",
      "title": "recognizedPoints(_:)",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyposeobservation/recognizedpoints(_:)"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanHandPoseObservation": {
      "abstract": [
        {
          "text": "An observation that provides the hand points the analysis recognized.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNHumanHandPoseObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanHandPoseObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanHandPoseObservation"
        }
      ],
      "role": "symbol",
      "title": "VNHumanHandPoseObservation",
      "type": "topic",
      "url": "/documentation/vision/vnhumanhandposeobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest/regionOfInterest": {
      "abstract": [
        {
          "text": "The region of the image in which Vision will perform the request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "regionOfInterest"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@CGRect",
          "text": "CGRect"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNImageBasedRequest/regionOfInterest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "regionOfInterest"
        }
      ],
      "role": "symbol",
      "title": "regionOfInterest",
      "type": "topic",
      "url": "/documentation/vision/vnimagebasedrequest/regionofinterest"
    },
    "doc://com.apple.vision/documentation/Vision/VNImagePointForNormalizedPoint(_:_:_:)": {
      "abstract": [
        {
          "text": "Projects a point in normalized coordinates into image coordinates.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNImagePointForNormalizedPoint"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@CGPoint",
          "text": "CGPoint"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Si",
          "text": "Int"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Si",
          "text": "Int"
        },
        {
          "kind": "text",
          "text": ") -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@CGPoint",
          "text": "CGPoint"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNImagePointForNormalizedPoint(_:_:_:)",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNImagePointForNormalizedPoint"
        }
      ],
      "role": "symbol",
      "title": "VNImagePointForNormalizedPoint(_:_:_:)",
      "type": "topic",
      "url": "/documentation/vision/vnimagepointfornormalizedpoint(_:_:_:)"
    },
    "doc://com.apple.vision/documentation/Vision/VNImageRequestHandler": {
      "abstract": [
        {
          "text": "An object that processes one or more image-analysis request pertaining to a single image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNImageRequestHandler"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNImageRequestHandler",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNImageRequestHandler"
        }
      ],
      "role": "symbol",
      "title": "VNImageRequestHandler",
      "type": "topic",
      "url": "/documentation/vision/vnimagerequesthandler"
    },
    "doc://com.apple.vision/documentation/Vision/VNObservation": {
      "abstract": [
        {
          "text": "The abstract superclass for analysis results.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNObservation"
        }
      ],
      "role": "symbol",
      "title": "VNObservation",
      "type": "topic",
      "url": "/documentation/vision/vnobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNPoint": {
      "abstract": [
        {
          "text": "An immutable object that represents a single 2D point in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNPoint"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNPoint",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNPoint"
        }
      ],
      "role": "symbol",
      "title": "VNPoint",
      "type": "topic",
      "url": "/documentation/vision/vnpoint"
    },
    "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint": {
      "abstract": [
        {
          "text": "An object that represents a normalized point in an image, along with an identifier label and a confidence value.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNRecognizedPoint"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNRecognizedPoint"
        }
      ],
      "role": "symbol",
      "title": "VNRecognizedPoint",
      "type": "topic",
      "url": "/documentation/vision/vnrecognizedpoint"
    },
    "doc://com.apple.vision/documentation/Vision/VNRecognizedPointGroupKey": {
      "abstract": [
        {
          "text": "The data type for all recognized-point group keys.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNRecognizedPointGroupKey"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPointGroupKey",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNRecognizedPointGroupKey"
        }
      ],
      "role": "symbol",
      "title": "VNRecognizedPointGroupKey",
      "type": "topic",
      "url": "/documentation/vision/vnrecognizedpointgroupkey"
    },
    "doc://com.apple.vision/documentation/Vision/VNRecognizedPointKey": {
      "abstract": [
        {
          "text": "The data type for all recognized point keys.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNRecognizedPointKey"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPointKey",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNRecognizedPointKey"
        }
      ],
      "role": "symbol",
      "title": "VNRecognizedPointKey",
      "type": "topic",
      "url": "/documentation/vision/vnrecognizedpointkey"
    },
    "doc://com.apple.vision/documentation/Vision/VNRecognizedPointsObservation": {
      "abstract": [
        {
          "text": "An observation that provides the points the analysis recognized.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNRecognizedPointsObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPointsObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNRecognizedPointsObservation"
        }
      ],
      "role": "symbol",
      "title": "VNRecognizedPointsObservation",
      "type": "topic",
      "url": "/documentation/vision/vnrecognizedpointsobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNRequest/results": {
      "abstract": [
        {
          "text": "The collection of ",
          "type": "text"
        },
        {
          "identifier": "doc://com.apple.vision/documentation/Vision/VNObservation",
          "isActive": true,
          "type": "reference"
        },
        {
          "text": " results generated by request processing.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "results"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNObservation",
          "text": "VNObservation"
        },
        {
          "kind": "text",
          "text": "]?"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRequest/results",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "results"
        }
      ],
      "role": "symbol",
      "title": "results",
      "type": "topic",
      "url": "/documentation/vision/vnrequest/results"
    },
    "doc://com.apple.vision/documentation/Vision/building-a-feature-rich-app-for-sports-analysis": {
      "abstract": [
        {
          "text": "Detect and classify human activity in real time using computer vision and machine learning.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/building-a-feature-rich-app-for-sports-analysis",
      "kind": "article",
      "role": "sampleCode",
      "title": "Building a feature-rich app for sports analysis",
      "type": "topic",
      "url": "/documentation/vision/building-a-feature-rich-app-for-sports-analysis"
    },
    "doc://com.apple.vision/documentation/Vision/detecting-hand-poses-with-vision": {
      "abstract": [
        {
          "text": "Create a virtual drawing app by using Vision’s capability to detect hand poses.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/detecting-hand-poses-with-vision",
      "kind": "article",
      "role": "sampleCode",
      "title": "Detecting Hand Poses with Vision",
      "type": "topic",
      "url": "/documentation/vision/detecting-hand-poses-with-vision"
    },
    "doc://com.apple.vision/documentation/Vision/original-objective-c-and-swift-api": {
      "abstract": [],
      "identifier": "doc://com.apple.vision/documentation/Vision/original-objective-c-and-swift-api",
      "kind": "article",
      "role": "collectionGroup",
      "title": "Original Objective-C and Swift API",
      "type": "topic",
      "url": "/documentation/vision/original-objective-c-and-swift-api"
    },
    "media-3625688": {
      "alt": "An illustration depicting a model of the human body. The body points that Vision detects are the right and left wrists, elbows, shoulders, ears, eyes, hips, knees, and ankles; and the nose, neck, and root, or center point.",
      "identifier": "media-3625688",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/fba5d5b4ffa9b8d7d659dbe698f427df/media-3625688@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/647adbdc4b788a1f0d619d247c073ea8/media-3625688~dark@2x.png"
        }
      ]
    }
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Body-and-hand-pose-detection",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/detecting-hand-poses-with-vision",
        "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPoseRequest",
        "doc://com.apple.vision/documentation/Vision/VNDetectHumanHandPoseRequest",
        "doc://com.apple.vision/documentation/Vision/VNRecognizedPointsObservation",
        "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation",
        "doc://com.apple.vision/documentation/Vision/VNHumanHandPoseObservation",
        "doc://com.apple.vision/documentation/Vision/VNPoint",
        "doc://com.apple.vision/documentation/Vision/VNDetectedPoint",
        "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint",
        "doc://com.apple.vision/documentation/Vision/VNRecognizedPointKey",
        "doc://com.apple.vision/documentation/Vision/VNRecognizedPointGroupKey"
      ],
      "title": "Body and hand pose detection"
    }
  ],
  "variantOverrides": [
    {
      "patch": [
        {
          "op": "replace",
          "path": "/identifier/interfaceLanguage",
          "value": "occ"
        },
        {
          "op": "add",
          "path": "/topicSections",
          "value": null
        },
        {
          "op": "replace",
          "path": "/seeAlsoSections",
          "value": [
            {
              "anchor": "Body-and-hand-pose-detection",
              "generated": true,
              "identifiers": [
                "doc://com.apple.vision/documentation/Vision/detecting-hand-poses-with-vision",
                "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPoseRequest",
                "doc://com.apple.vision/documentation/Vision/VNDetectHumanHandPoseRequest",
                "doc://com.apple.vision/documentation/Vision/VNRecognizedPointsObservation",
                "doc://com.apple.vision/documentation/Vision/VNHumanBodyPoseObservation",
                "doc://com.apple.vision/documentation/Vision/VNHumanHandPoseObservation",
                "doc://com.apple.vision/documentation/Vision/VNPoint",
                "doc://com.apple.vision/documentation/Vision/VNDetectedPoint",
                "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint",
                "doc://com.apple.vision/documentation/Vision/VNRecognizedPointKey",
                "doc://com.apple.vision/documentation/Vision/VNRecognizedPointGroupKey"
              ],
              "title": "Body and hand pose detection"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1coregraphics~1cgimage/title",
          "value": "CGImageRef"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNObservation/title",
          "value": "VNObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1JointsGroupName~1torso/title",
          "value": "VNHumanBodyPoseObservationJointsGroupNameTorso"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1JointsGroupName~1torso/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPoseObservationJointsGroupNameTorso"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation/title",
          "value": "VNHumanBodyPoseObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPoseObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPoseObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointKey/title",
          "value": "VNRecognizedPointKey"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointKey/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPointKey"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointKey/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPointKey"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanHandPoseRequest/title",
          "value": "VNDetectHumanHandPoseRequest"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanHandPoseRequest/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectHumanHandPoseRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanHandPoseRequest/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectHumanHandPoseRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPoint/title",
          "value": "VNPoint"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPoint/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPoint/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRequest~1results/title",
          "value": "results"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRequest~1results/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "results"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointsObservation/title",
          "value": "VNRecognizedPointsObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointsObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPointsObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointsObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPointsObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointGroupKey/title",
          "value": "VNRecognizedPointGroupKey"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointGroupKey/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPointGroupKey"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPointGroupKey/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPointGroupKey"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanHandPoseObservation/title",
          "value": "VNHumanHandPoseObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanHandPoseObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanHandPoseObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanHandPoseObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanHandPoseObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectedPoint/title",
          "value": "VNDetectedPoint"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectedPoint/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectedPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectedPoint/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectedPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1JointsGroupName/title",
          "value": "VNHumanBodyPoseObservationJointsGroupName"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1JointsGroupName/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPoseObservationJointsGroupName"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1JointsGroupName/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPoseObservationJointsGroupName"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageRequestHandler/title",
          "value": "VNImageRequestHandler"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageRequestHandler/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageRequestHandler"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageRequestHandler/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageRequestHandler"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanBodyPoseRequest/title",
          "value": "VNDetectHumanBodyPoseRequest"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanBodyPoseRequest/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectHumanBodyPoseRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanBodyPoseRequest/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectHumanBodyPoseRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectedPoint~1confidence/title",
          "value": "confidence"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectedPoint~1confidence/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "confidence"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1recognizedPoints(_:)/title",
          "value": "recognizedPointsForJointsGroupName:error:"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPoseObservation~1recognizedPoints(_:)/fragments",
          "value": [
            {
              "kind": "text",
              "text": "- "
            },
            {
              "kind": "identifier",
              "text": "recognizedPointsForJointsGroupName:error:"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoint/title",
          "value": "VNRecognizedPoint"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoint/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoint/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImagePointForNormalizedPoint(_:_:_:)/title",
          "value": "VNImagePointForNormalizedPoint"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImagePointForNormalizedPoint(_:_:_:)/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImagePointForNormalizedPoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageBasedRequest~1regionOfInterest/title",
          "value": "regionOfInterest"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageBasedRequest~1regionOfInterest/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "regionOfInterest"
            }
          ]
        }
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/detecting-human-body-poses-in-images"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    },
    {
      "paths": [
        "/documentation/vision/detecting-human-body-poses-in-images"
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ]
}
