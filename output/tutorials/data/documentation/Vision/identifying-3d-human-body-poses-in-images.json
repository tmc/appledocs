{
  "abstract": [
    {
      "text": "Detect three-dimensional human body poses using the Vision framework.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.vision/documentation/Vision",
        "doc://com.apple.vision/documentation/Vision/original-objective-c-and-swift-api"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.vision/documentation/Vision/identifying-3d-human-body-poses-in-images"
  },
  "kind": "article",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "modules": [
      {
        "name": "Vision"
      }
    ],
    "role": "article",
    "roleHeading": "Article",
    "title": "Identifying 3D human body poses in images"
  },
  "primaryContentSections": [
    {
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Vision allows you to take your app’s body pose detection into the third dimension. All photos — with people in them — are a 2D representation of people in a 3D world. Starting in iOS 17 and macOS 14, Vision detects human body poses and measures 17 individual joint locations in 3D space. You access a joint location using the joint name itself, or with a joint group name that returns a collection of joints. The following illustration of a 3D model identifies the 17 joint locations that Vision detects.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "identifier": "media-4288127",
              "type": "image"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Images you capture in Portrait mode using Camera — or using ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " — contain depth data that helps to detect distance for each pixel. If your content contains depth data, Vision fetches it automatically. With Vision, you can build an app that tracks a person performing an exercise in 3D space, follows the arm movement during a golf swing, or captures character animations for a video game.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "For more information about recognizing a body pose in 2D, see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-images",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Perform-a-body-pose-request",
          "level": 3,
          "text": "Perform a body pose request",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Detecting the position of the joints on a human body in 3D space begins with ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ". The request only supports the detection and results for the most prominent person in the frame, so it generates a single observation. For example, performing a request on an image with three people — with one person being closer to the camera — returns an observation that detects the person closest to the camera.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The observation contains a collection of 17 ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " objects that contain the 3D position of a joint you specify, and the parent joint it connects to. The framework doesn’t return a partial list of joints, so you get all 17 joints or none.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The request doesn’t require images with depth data to run. However, providing depth data improves detection accuracy.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "import Vision",
            "",
            "// Get an image from the project bundle. ",
            "guard let filePath = Bundle.main.path(forResource: \"bodypose\", ofType: \"heic\") else { ",
            "    return ",
            "} ",
            "let fileUrl = URL(fileURLWithPath: filePath) ",
            "",
            "// Create an object to process the request.  ",
            "let requestHandler = VNImageRequestHandler(url: fileUrl) ",
            "",
            "// Create a request to detect a body pose in 3D space. ",
            "let request = VNDetectHumanBodyPose3DRequest() ",
            "",
            "do {    ",
            "    // Perform the body pose request.    ",
            "    try requestHandler.perform([request])    ",
            "",
            "    // Get the observation.    ",
            "    if let observation = request.results?.first {        ",
            "        // Handle the observation.    ",
            "    }",
            "} catch {",
            "    print(\"Unable to perform the request: \\(error).\") ",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "anchor": "Handle-the-resulting-observation",
          "level": 3,
          "text": "Handle the resulting observation",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "A ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " provides body pose information in 3D space, in meters. The framework normalizes 2D points — from other framework requests — to a lower-left origin. Points that a 3D body pose request returns are relative to the scene in the real world, with an origin at the root joint, located between the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName/leftHip",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " and ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName/rightHip",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "To get a list of the available joint names, call ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest/supportedJointNames",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ". Joints are also grouped by their location on the body. For example, the left arm group provides the left shoulder, elbow and wrist joints. To get a list of the group names, call ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest/supportedJointsGroupNames",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "// Get a recognized joint by using a joint name. ",
            "let leftShoulder = try observation.recognizedPoint(.leftShoulder) ",
            "let leftElbow = try observation.recognizedPoint(.leftElbow) ",
            "let leftWrist = try observation.recognizedPoint(.leftWrist) ",
            "",
            "// Get a collection of joints by using a joint group name. ",
            "let leftArm = try observation.recognizedPoints(.leftArm)"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "If there’s enough depth metadata, ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/bodyHeight",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " provides an estimated height of the subject, in meters; otherwise, ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/bodyHeight",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " returns a reference height of ",
              "type": "text"
            },
            {
              "code": "1.8",
              "type": "codeVoice"
            },
            {
              "text": " meters. The framework provides a measured height only when configuring an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation/AVCaptureSession",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " to use the LiDAR camera. For more information about configuring your session, see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation/capturing-depth-using-the-lidar-camera",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "identifier": "media-4292420",
              "type": "image"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Use ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/cameraRelativePosition(_:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " to get an estimate of how far the person was away from a camera. To get an accurate understanding of where the camera was when capturing the image, use ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/cameraOriginMatrix",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Work-with-positions-in-3D-space",
          "level": 3,
          "text": "Work with positions in 3D space",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "The Vision frameworks represents a 3D position as a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/simd/simd_float4x4",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " matrix. A ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object contains the position of the joint, in meters, along with an identifier that corresponds to the joint name. It also contains the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/localPosition",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " of the joint, which describes the position relative to a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/parentJoint",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "",
                  "type": "text"
                },
                {
                  "text": " ",
                  "type": "text"
                },
                {
                  "text": "A joint’s position is always relative to the root joint.",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Important",
          "style": "important",
          "type": "aside"
        },
        {
          "inlineContent": [
            {
              "text": "Use ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/pointInImage(_:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " to project a 3D joint coordinate back to a 2D input image for the body joint you specify. For instance, if you want to align the 3D body pose with the 2D input image, use ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/pointInImage(_:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " to get the root joint position in the input image.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "A ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/localPosition",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " is useful if your app is only working with one area of the body, and simplifies determining the angle between a child and parent joint.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "import simd ",
            "",
            "var angleVector: simd_float3 = simd_float3() ",
            "",
            "// Get the position relative to the parent shoulder joint. ",
            "let childPosition = leftElbow.localPosition ",
            "let translationChild = simd_make_float3(childPosition.columns.3[0], ",
            "                                        childPosition.columns.3[1], ",
            "                                        childPosition.columns.3[2]) ",
            "",
            "// The rotation around the x-axis. ",
            "let pitch = (Float.pi / 2) ",
            "",
            "// The rotation around the y-axis. ",
            "let yaw = acos(translationChild.z / simd_length(translationChild)) ",
            "",
            "// The rotation around the z-axis. ",
            "let roll = atan2((translationChild.y), (translationChild.x)) ",
            "",
            "// The angle between the elbow and shoulder joint. ",
            "angleVector = simd_float3(pitch, yaw, roll)"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "For more information about matrices, see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/Accelerate/working-with-matrices",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Use-depth-data-as-input",
          "level": 3,
          "text": "Use depth data as input",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Depth data contains the information the system needs to reconstruct a 3D scene, and includes camera calibration data. ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation/AVDepthData",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " serves as the container class for interfacing with depth metadata. Starting in iOS 17 and macOS 14, provide depth data when you initialize a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.vision/documentation/Vision/VNImageRequestHandler",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " with sample or pixel buffers.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Images you capture using Photo mode in Camera store depth as disparity maps — a 2D map reduced from 3D space — with calibration data. You can also configure your ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation/AVCaptureSession",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " to use LiDAR to get depth data. For more information about working with depth, see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation/capturing-photos-with-depth",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " and ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AVFoundation/enhancing-live-video-by-leveraging-truedepth-camera-data",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/AVFoundation": {
      "abstract": [
        {
          "text": "Work with audiovisual assets, control device cameras, process audio, and configure system audio interactions.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AVFoundation",
      "kind": "symbol",
      "role": "collection",
      "title": "AVFoundation",
      "type": "topic",
      "url": "/documentation/AVFoundation"
    },
    "doc://com.apple.documentation/documentation/AVFoundation/AVCaptureSession": {
      "abstract": [
        {
          "text": "An object that configures capture behavior and coordinates the flow of data from input devices to capture outputs.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "AVCaptureSession"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AVFoundation/AVCaptureSession",
      "kind": "symbol",
      "role": "symbol",
      "title": "AVCaptureSession",
      "type": "topic",
      "url": "/documentation/AVFoundation/AVCaptureSession"
    },
    "doc://com.apple.documentation/documentation/AVFoundation/AVDepthData": {
      "abstract": [
        {
          "text": "A container for per-pixel distance or disparity information captured by compatible camera devices.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "AVDepthData"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AVFoundation/AVDepthData",
      "kind": "symbol",
      "role": "symbol",
      "title": "AVDepthData",
      "type": "topic",
      "url": "/documentation/AVFoundation/AVDepthData"
    },
    "doc://com.apple.documentation/documentation/AVFoundation/capturing-depth-using-the-lidar-camera": {
      "abstract": [
        {
          "text": "Access the LiDAR camera on supporting devices to capture precise depth data.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AVFoundation/capturing-depth-using-the-lidar-camera",
      "kind": "article",
      "role": "sampleCode",
      "title": "Capturing depth using the LiDAR camera",
      "type": "topic",
      "url": "/documentation/AVFoundation/capturing-depth-using-the-lidar-camera"
    },
    "doc://com.apple.documentation/documentation/AVFoundation/capturing-photos-with-depth": {
      "abstract": [
        {
          "text": "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AVFoundation/capturing-photos-with-depth",
      "kind": "article",
      "role": "article",
      "title": "Capturing Photos with Depth",
      "type": "topic",
      "url": "/documentation/AVFoundation/capturing-photos-with-depth"
    },
    "doc://com.apple.documentation/documentation/AVFoundation/enhancing-live-video-by-leveraging-truedepth-camera-data": {
      "abstract": [
        {
          "text": "Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AVFoundation/enhancing-live-video-by-leveraging-truedepth-camera-data",
      "kind": "article",
      "role": "sampleCode",
      "title": "Enhancing Live Video by Leveraging TrueDepth Camera Data",
      "type": "topic",
      "url": "/documentation/AVFoundation/enhancing-live-video-by-leveraging-truedepth-camera-data"
    },
    "doc://com.apple.documentation/documentation/Accelerate/working-with-matrices": {
      "abstract": [
        {
          "text": "Solve simultaneous equations and transform points in space.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/Accelerate/working-with-matrices",
      "kind": "article",
      "role": "article",
      "title": "Working with Matrices",
      "type": "topic",
      "url": "/documentation/Accelerate/working-with-matrices"
    },
    "doc://com.apple.documentation/documentation/simd/simd_float4x4": {
      "abstract": [
        {
          "text": "A matrix of four columns and four rows that contains single-precision values.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "simd_float4x4"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/simd/simd_float4x4",
      "kind": "symbol",
      "role": "symbol",
      "title": "simd_float4x4",
      "type": "topic",
      "url": "/documentation/simd/simd_float4x4"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.vision/documentation/Vision": {
      "abstract": [
        {
          "text": "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision",
      "kind": "symbol",
      "role": "collection",
      "title": "Vision",
      "type": "topic",
      "url": "/documentation/vision"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest": {
      "abstract": [
        {
          "text": "A request that detects points on human bodies in 3D space, relative to the camera.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNDetectHumanBodyPose3DRequest"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNDetectHumanBodyPose3DRequest"
        }
      ],
      "role": "symbol",
      "title": "VNDetectHumanBodyPose3DRequest",
      "type": "topic",
      "url": "/documentation/vision/vndetecthumanbodypose3drequest"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest/supportedJointNames": {
      "abstract": [
        {
          "text": "Returns the joint group names the request supports.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supportedJointNames"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointName",
          "text": "JointName"
        },
        {
          "kind": "text",
          "text": "]"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest/supportedJointNames",
      "kind": "symbol",
      "role": "symbol",
      "title": "supportedJointNames",
      "type": "topic",
      "url": "/documentation/vision/vndetecthumanbodypose3drequest/supportedjointnames"
    },
    "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest/supportedJointsGroupNames": {
      "abstract": [
        {
          "text": "Returns the joint names the request supports.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supportedJointsGroupNames"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointsGroupName",
          "text": "JointsGroupName"
        },
        {
          "kind": "text",
          "text": "]"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest/supportedJointsGroupNames",
      "kind": "symbol",
      "role": "symbol",
      "title": "supportedJointsGroupNames",
      "type": "topic",
      "url": "/documentation/vision/vndetecthumanbodypose3drequest/supportedjointsgroupnames"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation": {
      "abstract": [
        {
          "text": "An observation that provides the 3D body points the request recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNHumanBodyPose3DObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanBodyPose3DObservation"
        }
      ],
      "role": "symbol",
      "title": "VNHumanBodyPose3DObservation",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName": {
      "abstract": [
        {
          "text": "The joint names for a 3D body pose.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "JointName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "JointName"
        }
      ],
      "role": "symbol",
      "title": "VNHumanBodyPose3DObservation.JointName",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/jointname"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName/leftHip": {
      "abstract": [
        {
          "text": "A joint name that represents the left hip.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "leftHip"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointName",
          "text": "JointName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName/leftHip",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanBodyPose3DObservationJointNameLeftHip"
        }
      ],
      "role": "symbol",
      "title": "leftHip",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/jointname/lefthip"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName/rightHip": {
      "abstract": [
        {
          "text": "A joint name that represents the right hip.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "rightHip"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointName",
          "text": "JointName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName/rightHip",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanBodyPose3DObservationJointNameRightHip"
        }
      ],
      "role": "symbol",
      "title": "rightHip",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/jointname/righthip"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointsGroupName": {
      "abstract": [
        {
          "text": "The joint group names for a 3D body pose.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "JointsGroupName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointsGroupName",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "JointsGroupName"
        }
      ],
      "role": "symbol",
      "title": "VNHumanBodyPose3DObservation.JointsGroupName",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/jointsgroupname"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/bodyHeight": {
      "abstract": [
        {
          "text": "The estimated human body height, in meters.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "bodyHeight"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Sf",
          "text": "Float"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/bodyHeight",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "bodyHeight"
        }
      ],
      "role": "symbol",
      "title": "bodyHeight",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/bodyheight"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/cameraOriginMatrix": {
      "abstract": [
        {
          "text": "A transform from the skeleton hip to the camera.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "cameraOriginMatrix"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@SA@simd_float4x4",
          "text": "simd_float4x4"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/cameraOriginMatrix",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "cameraOriginMatrix"
        }
      ],
      "role": "symbol",
      "title": "cameraOriginMatrix",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/cameraoriginmatrix"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/cameraRelativePosition(_:)": {
      "abstract": [
        {
          "text": "Returns a position relative to the camera for the body joint you specify.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "cameraRelativePosition"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointName",
          "text": "JointName"
        },
        {
          "kind": "text",
          "text": ") "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@SA@simd_float4x4",
          "text": "simd_float4x4"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/cameraRelativePosition(_:)",
      "kind": "symbol",
      "role": "symbol",
      "title": "cameraRelativePosition(_:)",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/camerarelativeposition(_:)"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/pointInImage(_:)": {
      "abstract": [
        {
          "text": "Returns a 2D point for the joint name you specify, relative to the input image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "pointInImage"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointName",
          "text": "JointName"
        },
        {
          "kind": "text",
          "text": ") "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNPoint",
          "text": "VNPoint"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/pointInImage(_:)",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "pointInImageForJointName:error:"
        }
      ],
      "role": "symbol",
      "title": "pointInImage(_:)",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodypose3dobservation/pointinimage(_:)"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D": {
      "abstract": [
        {
          "text": "A recognized 3D point that includes a parent joint.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNHumanBodyRecognizedPoint3D"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNHumanBodyRecognizedPoint3D"
        }
      ],
      "role": "symbol",
      "title": "VNHumanBodyRecognizedPoint3D",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyrecognizedpoint3d"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/localPosition": {
      "abstract": [
        {
          "text": "The three-dimensional position.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "localPosition"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@SA@simd_float4x4",
          "text": "simd_float4x4"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/localPosition",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "localPosition"
        }
      ],
      "role": "symbol",
      "title": "localPosition",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyrecognizedpoint3d/localposition"
    },
    "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/parentJoint": {
      "abstract": [
        {
          "text": "The parent joint in the observation.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "parentJoint"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)VNHumanBodyPose3DObservation",
          "text": "VNHumanBodyPose3DObservation"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@T@VNHumanBodyPose3DObservationJointName",
          "text": "JointName"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D/parentJoint",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "parentJoint"
        }
      ],
      "role": "symbol",
      "title": "parentJoint",
      "type": "topic",
      "url": "/documentation/vision/vnhumanbodyrecognizedpoint3d/parentjoint"
    },
    "doc://com.apple.vision/documentation/Vision/VNImageRequestHandler": {
      "abstract": [
        {
          "text": "An object that processes one or more image-analysis request pertaining to a single image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNImageRequestHandler"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNImageRequestHandler",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNImageRequestHandler"
        }
      ],
      "role": "symbol",
      "title": "VNImageRequestHandler",
      "type": "topic",
      "url": "/documentation/vision/vnimagerequesthandler"
    },
    "doc://com.apple.vision/documentation/Vision/VNPoint3D": {
      "abstract": [
        {
          "text": "An object that represents a 3D point in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNPoint3D"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNPoint3D",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNPoint3D"
        }
      ],
      "role": "symbol",
      "title": "VNPoint3D",
      "type": "topic",
      "url": "/documentation/vision/vnpoint3d"
    },
    "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint3D": {
      "abstract": [
        {
          "text": "A 3D point that includes an identifier to the point.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNRecognizedPoint3D"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint3D",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNRecognizedPoint3D"
        }
      ],
      "role": "symbol",
      "title": "VNRecognizedPoint3D",
      "type": "topic",
      "url": "/documentation/vision/vnrecognizedpoint3d"
    },
    "doc://com.apple.vision/documentation/Vision/VNRecognizedPoints3DObservation": {
      "abstract": [
        {
          "text": "An observation that provides the 3D points for a request.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "VNRecognizedPoints3DObservation"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/VNRecognizedPoints3DObservation",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "VNRecognizedPoints3DObservation"
        }
      ],
      "role": "symbol",
      "title": "VNRecognizedPoints3DObservation",
      "type": "topic",
      "url": "/documentation/vision/vnrecognizedpoints3dobservation"
    },
    "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-3d-with-vision": {
      "abstract": [
        {
          "text": "Render skeletons of 3D body pose points in a scene overlaying the input image.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-3d-with-vision",
      "kind": "article",
      "role": "sampleCode",
      "title": "Detecting human body poses in 3D with Vision",
      "type": "topic",
      "url": "/documentation/vision/detecting-human-body-poses-in-3d-with-vision"
    },
    "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-images": {
      "abstract": [
        {
          "text": "Add the capability to detect human body poses to your app using the Vision framework.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-images",
      "kind": "article",
      "role": "article",
      "title": "Detecting Human Body Poses in Images",
      "type": "topic",
      "url": "/documentation/vision/detecting-human-body-poses-in-images"
    },
    "doc://com.apple.vision/documentation/Vision/original-objective-c-and-swift-api": {
      "abstract": [],
      "identifier": "doc://com.apple.vision/documentation/Vision/original-objective-c-and-swift-api",
      "kind": "article",
      "role": "collectionGroup",
      "title": "Original Objective-C and Swift API",
      "type": "topic",
      "url": "/documentation/vision/original-objective-c-and-swift-api"
    },
    "media-4288127": {
      "alt": "An illustration depicting a 3D model of the human body. The body points that Vision detects are the right and left wrists, elbows, shoulders, hips, knees, and ankles; the top and center of the head, the spine, the root that’s a point between the hips, and a center shoulder point between the shoulders.",
      "identifier": "media-4288127",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/7939e90f7e2e46abf55c61682356e1f3/media-4288127@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/3d2afb07a4ce110ba74e8bb92c88bb8d/media-4288127~dark@2x.png"
        }
      ]
    },
    "media-4292420": {
      "alt": "An illustration depicting a three-dimensional model of the human body and a camera. The camera points at the body pose and indicates where a person took the photo in relation to the body pose.",
      "identifier": "media-4292420",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/050956dac0bd5eb905b90be303e1905f/media-4292420@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/43c30491b31847d7f91737ddb6da2082/media-4292420~dark@2x.png"
        }
      ]
    }
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "3D-body-pose-detection",
      "generated": true,
      "identifiers": [
        "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-3d-with-vision",
        "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest",
        "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation",
        "doc://com.apple.vision/documentation/Vision/VNRecognizedPoints3DObservation",
        "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D",
        "doc://com.apple.vision/documentation/Vision/VNPoint3D",
        "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint3D",
        "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName",
        "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointsGroupName"
      ],
      "title": "3D body pose detection"
    }
  ],
  "variantOverrides": [
    {
      "patch": [
        {
          "op": "replace",
          "path": "/identifier/interfaceLanguage",
          "value": "occ"
        },
        {
          "op": "add",
          "path": "/topicSections",
          "value": null
        },
        {
          "op": "replace",
          "path": "/seeAlsoSections",
          "value": [
            {
              "anchor": "3D-body-pose-detection",
              "generated": true,
              "identifiers": [
                "doc://com.apple.vision/documentation/Vision/detecting-human-body-poses-in-3d-with-vision",
                "doc://com.apple.vision/documentation/Vision/VNDetectHumanBodyPose3DRequest",
                "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation",
                "doc://com.apple.vision/documentation/Vision/VNRecognizedPoints3DObservation",
                "doc://com.apple.vision/documentation/Vision/VNHumanBodyRecognizedPoint3D",
                "doc://com.apple.vision/documentation/Vision/VNPoint3D",
                "doc://com.apple.vision/documentation/Vision/VNRecognizedPoint3D",
                "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointName",
                "doc://com.apple.vision/documentation/Vision/VNHumanBodyPose3DObservation/JointsGroupName"
              ],
              "title": "3D body pose detection"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPoint3D/title",
          "value": "VNPoint3D"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPoint3D/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNPoint3D"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNPoint3D/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNPoint3D"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D~1parentJoint/title",
          "value": "parentJoint"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D~1parentJoint/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "parentJoint"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1cameraOriginMatrix/title",
          "value": "cameraOriginMatrix"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1cameraOriginMatrix/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "cameraOriginMatrix"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation/title",
          "value": "VNHumanBodyPose3DObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoint3D/title",
          "value": "VNRecognizedPoint3D"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoint3D/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPoint3D"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoint3D/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPoint3D"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1AVFoundation~1AVCaptureSession/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@interface"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "AVCaptureSession"
            },
            {
              "kind": "text",
              "text": " : "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)NSObject",
              "text": "NSObject"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoints3DObservation/title",
          "value": "VNRecognizedPoints3DObservation"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoints3DObservation/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPoints3DObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNRecognizedPoints3DObservation/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNRecognizedPoints3DObservation"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageRequestHandler/title",
          "value": "VNImageRequestHandler"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageRequestHandler/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageRequestHandler"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNImageRequestHandler/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNImageRequestHandler"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1pointInImage(_:)/title",
          "value": "pointInImageForJointName:error:"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1pointInImage(_:)/fragments",
          "value": [
            {
              "kind": "text",
              "text": "- "
            },
            {
              "kind": "identifier",
              "text": "pointInImageForJointName:error:"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1AVFoundation~1AVDepthData/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@interface"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "AVDepthData"
            },
            {
              "kind": "text",
              "text": " : "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)NSObject",
              "text": "NSObject"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1simd~1simd_float4x4/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "typedef"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "keyword",
              "text": "struct"
            },
            {
              "kind": "text",
              "text": " { ... } "
            },
            {
              "kind": "identifier",
              "text": "simd_float4x4"
            },
            {
              "kind": "text",
              "text": ";"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D/title",
          "value": "VNHumanBodyRecognizedPoint3D"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyRecognizedPoint3D"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyRecognizedPoint3D"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointsGroupName/title",
          "value": "VNHumanBodyPose3DObservationJointsGroupName"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointsGroupName/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservationJointsGroupName"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointsGroupName/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservationJointsGroupName"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanBodyPose3DRequest/title",
          "value": "VNDetectHumanBodyPose3DRequest"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanBodyPose3DRequest/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectHumanBodyPose3DRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNDetectHumanBodyPose3DRequest/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNDetectHumanBodyPose3DRequest"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1bodyHeight/title",
          "value": "bodyHeight"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1bodyHeight/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "bodyHeight"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName/title",
          "value": "VNHumanBodyPose3DObservationJointName"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservationJointName"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName/navigatorTitle",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservationJointName"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D~1localPosition/title",
          "value": "localPosition"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyRecognizedPoint3D~1localPosition/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "localPosition"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName~1leftHip/title",
          "value": "VNHumanBodyPose3DObservationJointNameLeftHip"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName~1leftHip/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservationJointNameLeftHip"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName~1rightHip/title",
          "value": "VNHumanBodyPose3DObservationJointNameRightHip"
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.vision~1documentation~1Vision~1VNHumanBodyPose3DObservation~1JointName~1rightHip/fragments",
          "value": [
            {
              "kind": "identifier",
              "text": "VNHumanBodyPose3DObservationJointNameRightHip"
            }
          ]
        }
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/vision/identifying-3d-human-body-poses-in-images"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    },
    {
      "paths": [
        "/documentation/vision/identifying-3d-human-body-poses-in-images"
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ]
}
