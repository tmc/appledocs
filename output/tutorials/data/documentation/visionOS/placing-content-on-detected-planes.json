{
  "abstract": [
    {
      "text": "Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.visionOS/documentation/visionOS"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.visionOS/documentation/visionOS/placing-content-on-detected-planes"
  },
  "kind": "article",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "platforms": [
      {
        "beta": false,
        "introducedAt": "1.0",
        "name": "visionOS"
      },
      {
        "beta": false,
        "introducedAt": "15.1",
        "name": "Xcode"
      }
    ],
    "role": "sampleCode",
    "roleHeading": "Sample Code",
    "title": "Placing content on detected planes"
  },
  "primaryContentSections": [
    {
      "content": [
        {
          "anchor": "Overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Flat surfaces are an ideal place to position content in an app that uses a Full Space in visionOS. They provide a place for virtual 3D content to live alongside a person’s surroundings. Use plane detection in ARKit to detect these kinds of surfaces and filter the available planes based on criteria your app might need, such as the size of the plane, its proximity to someone, or a required plane orientation.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "identifier": "plane-detection.mp4",
          "type": "video"
        },
        {
          "anchor": "Use-RealityKit-anchor-entities-for-basic-plane-anchoring",
          "level": 3,
          "text": "Use RealityKit anchor entities for basic plane anchoring",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "If you don’t need a specific plane in your app and you’re rendering your app’s 3D content in RealityKit, you can use an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/RealityKit/AnchorEntity",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " instead. This approach lets you attach 3D content to a plane without prompting the person for world-sensing permission and without any particular knowledge of where that plane is relative to the person.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The following shows an anchor that you can use to attach entities to a table:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "AnchorEntity(.plane(.horizontal, classification: .table, minimumBounds: [0.5, 0.5]))"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "Anchor entities don’t let you choose a specific plane in a person’s surroundings, but rather let you ask for a plane with certain characteristics. When you need more specific plane selection or real-time information about the plane’s position and orientation in the world, use ",
              "type": "text"
            },
            {
              "code": "ARKitSession",
              "type": "codeVoice"
            },
            {
              "text": " and ",
              "type": "text"
            },
            {
              "code": "PlaneDetectionProvider",
              "type": "codeVoice"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Configure-an-ARKit-session-for-plane-detection",
          "level": 3,
          "text": "Configure an ARKit session for plane detection",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Plane-detection information comes from an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/ARKitSession",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " that’s configured to use a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/PlaneDetectionProvider",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ". You can choose to detect horizontal planes, vertical planes, or both. Each plane that ARKit detects comes with a classification, like ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/PlaneAnchor/Classification-swift.enum/table",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " or ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/PlaneAnchor/Classification-swift.enum/floor",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ". You can use these classifications to further refine which kinds of planes your app uses to present content. Plane detection requires ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/ARKitSession/AuthorizationType/worldSensing",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " authorization.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The following starts a session that detects both horizontal and vertical planes, but filters out planes classified as windows:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "let session = ARKitSession()",
            "let planeData = PlaneDetectionProvider(alignments: [.horizontal, .vertical])",
            "",
            "Task {",
            "    try await session.run([planeData])",
            "    ",
            "    for await update in planeData.anchorUpdates {",
            "        if update.anchor.classification == .window {",
            "            // Skip planes that are windows.",
            "            continue",
            "        }",
            "        switch update.event {",
            "        case .added, .updated:",
            "            await updatePlane(update.anchor)",
            "        case .removed:",
            "            await removePlane(update.anchor)",
            "        }",
            "        ",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "anchor": "Create-and-update-entities-associated-with-each-plane",
          "level": 3,
          "text": "Create and update entities associated with each plane",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "If you’re displaying content that needs to appear attached to a particular plane, update your content whenever you receive new information from ARKit. When a plane is no longer available in the person’s surroundings, ARKit sends a removal event. Respond to these events by removing content associated with the plane.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "The following shows plane updates that place a text entity on each plane in a person’s surroundings; the text entity displays the kind of plane ARKit detected:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "@MainActor var planeAnchors: [UUID: PlaneAnchor] = [:]",
            "@MainActor var entityMap: [UUID: Entity] = [:]",
            "",
            "@MainActor",
            "func updatePlane(_ anchor: PlaneAnchor) {",
            "    if planeAnchors[anchor.id] == nil {",
            "        // Add a new entity to represent this plane.",
            "        let entity = ModelEntity(mesh: .generateText(anchor.classification.description))",
            "        entityMap[anchor.id] = entity",
            "        rootEntity.addChild(entity)",
            "    }",
            "    ",
            "    entityMap[anchor.id]?.transform = Transform(matrix: anchor.originFromAnchorTransform)",
            "}",
            "",
            "@MainActor",
            "func removePlane(_ anchor: PlaneAnchor) {",
            "    entityMap[anchor.id]?.removeFromParent()",
            "    entityMap.removeValue(forKey: anchor.id)",
            "    planeAnchors.removeValue(forKey: anchor.id)",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "Building-local-experiences-with-room-tracking-PageImage-card.png": {
      "alt": "A view into the corner of a room with an open doorway, where one wall is a portal to a virtual universe.",
      "identifier": "Building-local-experiences-with-room-tracking-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/ecb2f88d37f7bba036c739568409febf/Building-local-experiences-with-room-tracking-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/af99ba5e2e307907caed07d89553f518/Building-local-experiences-with-room-tracking-PageImage-card~dark@2x.png"
        }
      ]
    },
    "Happy-Beam-intro.png": {
      "alt": "A screenshot showing the Happy Beam game. A player makes a heart gesture with their hands, a beam projects from it aimed at nearby clouds, and a scoreboard window shows seven points.",
      "identifier": "Happy-Beam-intro.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/52b497b6d705af322726d7371dee6ddd/Happy-Beam-intro@2x.png"
        }
      ]
    },
    "Object-Tracking-PageImage-card.png": {
      "alt": "An image of a room with several rectangular tiers on which glowing and textured, reflective spheres rest.",
      "identifier": "Object-Tracking-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/dfd3696d1b7df884ded8407cef3e8045/Object-Tracking-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/2332d74827799a86de0261e14c5a61f5/Object-Tracking-PageImage-card~dark@2x.png"
        }
      ]
    },
    "c52a77b613db/ObjectPlacementExample.zip": {
      "checksum": "c52a77b613dba228258fffa868dbbafa861941d02c1baf200eccef14f41fa60f4b276d231852ca93f5abe1e94c3a1a449da561bd3ff4c43c0906d578067f0af5",
      "identifier": "c52a77b613db/ObjectPlacementExample.zip",
      "type": "download",
      "url": "https://docs-assets.developer.apple.com/published/c52a77b613db/ObjectPlacementExample.zip"
    },
    "doc://com.apple.documentation/documentation/ARKit/ARKitSession": {
      "abstract": [
        {
          "text": "The main entry point for receiving data from ARKit.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "final"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ARKitSession"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/ARKitSession",
      "kind": "symbol",
      "role": "symbol",
      "title": "ARKitSession",
      "type": "topic",
      "url": "/documentation/ARKit/ARKitSession"
    },
    "doc://com.apple.documentation/documentation/ARKit/ARKitSession/AuthorizationType/worldSensing": {
      "abstract": [
        {
          "text": "The authorization for access to plane detection, scene reconstruction, and image tracking.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "case"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "worldSensing"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/ARKitSession/AuthorizationType/worldSensing",
      "kind": "symbol",
      "role": "symbol",
      "title": "ARKitSession.AuthorizationType.worldSensing",
      "type": "topic",
      "url": "/documentation/ARKit/ARKitSession/AuthorizationType/worldSensing"
    },
    "doc://com.apple.documentation/documentation/ARKit/PlaneAnchor/Classification-swift.enum/floor": {
      "abstract": [
        {
          "text": "A floor.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "case"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "floor"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/PlaneAnchor/Classification-swift.enum/floor",
      "kind": "symbol",
      "role": "symbol",
      "title": "PlaneAnchor.Classification.floor",
      "type": "topic",
      "url": "/documentation/ARKit/PlaneAnchor/Classification-swift.enum/floor"
    },
    "doc://com.apple.documentation/documentation/ARKit/PlaneAnchor/Classification-swift.enum/table": {
      "abstract": [
        {
          "text": "A table.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "case"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "table"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/PlaneAnchor/Classification-swift.enum/table",
      "kind": "symbol",
      "role": "symbol",
      "title": "PlaneAnchor.Classification.table",
      "type": "topic",
      "url": "/documentation/ARKit/PlaneAnchor/Classification-swift.enum/table"
    },
    "doc://com.apple.documentation/documentation/ARKit/PlaneDetectionProvider": {
      "abstract": [
        {
          "text": "A source of live data about planes in a person’s surroundings.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "final"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "PlaneDetectionProvider"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/PlaneDetectionProvider",
      "kind": "symbol",
      "role": "symbol",
      "title": "PlaneDetectionProvider",
      "type": "topic",
      "url": "/documentation/ARKit/PlaneDetectionProvider"
    },
    "doc://com.apple.documentation/documentation/RealityKit/AnchorEntity": {
      "abstract": [
        {
          "text": "An anchor that tethers entities to a scene.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "attribute",
          "text": "@"
        },
        {
          "kind": "attribute",
          "preciseIdentifier": "s:ScM",
          "text": "MainActor"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "attribute",
          "text": "@preconcurrency"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "AnchorEntity"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/RealityKit/AnchorEntity",
      "kind": "symbol",
      "role": "symbol",
      "title": "AnchorEntity",
      "type": "topic",
      "url": "/documentation/RealityKit/AnchorEntity"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.visionOS/documentation/visionOS": {
      "abstract": [
        {
          "text": "Create a new universe of apps and games for Apple Vision Pro.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS",
      "images": [
        {
          "identifier": "headset-orange.svg",
          "type": "icon"
        },
        {
          "identifier": "visionOS-PageImage-card.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "collection",
      "title": "visionOS",
      "type": "topic",
      "url": "/documentation/visionos"
    },
    "doc://com.apple.visionOS/documentation/visionOS/building_local_experiences_with_room_tracking": {
      "abstract": [
        {
          "text": "Use room tracking in visionOS to provide custom interactions with physical spaces.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/building_local_experiences_with_room_tracking",
      "images": [
        {
          "identifier": "Building-local-experiences-with-room-tracking-PageImage-card.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "sampleCode",
      "title": "Building local experiences with room tracking",
      "type": "topic",
      "url": "/documentation/visionos/building_local_experiences_with_room_tracking"
    },
    "doc://com.apple.visionOS/documentation/visionOS/exploring_object_tracking_with_arkit": {
      "abstract": [
        {
          "text": "Find and track real-world objects in visionOS using reference objects trained with Create ML.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/exploring_object_tracking_with_arkit",
      "images": [
        {
          "identifier": "Object-Tracking-PageImage-card.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "sampleCode",
      "title": "Exploring object tracking with ARKit",
      "type": "topic",
      "url": "/documentation/visionos/exploring_object_tracking_with_arkit"
    },
    "doc://com.apple.visionOS/documentation/visionOS/happybeam": {
      "abstract": [
        {
          "text": "Leverage a Full Space to create a fun game using ARKit.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/happybeam",
      "images": [
        {
          "identifier": "Happy-Beam-intro.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "sampleCode",
      "title": "Happy Beam",
      "type": "topic",
      "url": "/documentation/visionos/happybeam"
    },
    "doc://com.apple.visionOS/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience": {
      "abstract": [
        {
          "text": "Create an immersive experience by making your app’s content respond to the local shape of the world.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience",
      "kind": "article",
      "role": "sampleCode",
      "title": "Incorporating real-world surroundings in an immersive experience",
      "type": "topic",
      "url": "/documentation/visionos/incorporating-real-world-surroundings-in-an-immersive-experience"
    },
    "doc://com.apple.visionOS/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences": {
      "abstract": [
        {
          "text": "Use object tracking in visionOS to attach digital content to real objects to create engaging experiences.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences",
      "kind": "article",
      "role": "sampleCode",
      "title": "Object tracking with Reality Composer Pro experiences",
      "type": "topic",
      "url": "/documentation/visionos/object-tracking-with-reality-composer-pro-experiences"
    },
    "doc://com.apple.visionOS/documentation/visionOS/placing-entities-using-head-and-device-transform": {
      "abstract": [
        {
          "text": "Query and react to changes in the position and rotation of Apple Vision Pro.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/placing-entities-using-head-and-device-transform",
      "kind": "article",
      "role": "sampleCode",
      "title": "Placing entities using head and device transform",
      "type": "topic",
      "url": "/documentation/visionos/placing-entities-using-head-and-device-transform"
    },
    "doc://com.apple.visionOS/documentation/visionOS/setting-up-access-to-arkit-data": {
      "abstract": [
        {
          "text": "Check whether your app can use ARKit and respect people’s privacy.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/setting-up-access-to-arkit-data",
      "kind": "article",
      "role": "article",
      "title": "Setting up access to ARKit data",
      "type": "topic",
      "url": "/documentation/visionos/setting-up-access-to-arkit-data"
    },
    "doc://com.apple.visionOS/documentation/visionOS/tracking-images-in-3d-space": {
      "abstract": [
        {
          "text": "Place content based on the current position of a known image in a person’s surroundings.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/tracking-images-in-3d-space",
      "kind": "article",
      "role": "article",
      "title": "Tracking preregistered images in 3D space",
      "type": "topic",
      "url": "/documentation/visionos/tracking-images-in-3d-space"
    },
    "doc://com.apple.visionOS/documentation/visionOS/tracking-points-in-world-space": {
      "abstract": [
        {
          "text": "Retrieve the position and orientation of anchors your app stores in ARKit.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/tracking-points-in-world-space",
      "kind": "article",
      "role": "sampleCode",
      "title": "Tracking specific points in world space",
      "type": "topic",
      "url": "/documentation/visionos/tracking-points-in-world-space"
    },
    "headset-orange.svg": {
      "alt": "An icon representing visionOS.",
      "identifier": "headset-orange.svg",
      "type": "image",
      "variants": [
        {
          "svgID": "a",
          "traits": [
            "1x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/77dc6a0821bfb2da8db4a3b2033e6f6b/headset-orange.svg"
        }
      ]
    },
    "plane-detection-poster.png": {
      "alt": null,
      "identifier": "plane-detection-poster.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/489bb2a47b4d304961102201b4e8d752/plane-detection-poster@2x.png"
        }
      ]
    },
    "plane-detection.mp4": {
      "alt": "A video that pans across a room showing a debug visualization of detected planes. Each plane has a label for the type of plane, including a table, a wall, and a floor. The visualization's plane extents match the shape of the item, so the table visualization is round to match the round table and the others are rectangles.",
      "identifier": "plane-detection.mp4",
      "poster": "plane-detection-poster.png",
      "type": "video",
      "variants": [
        {
          "traits": [
            "1x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/364b575a694972747bab316a6e17615d/plane-detection.mp4"
        }
      ]
    },
    "visionOS-PageImage-card.png": {
      "alt": "A stylized illustration of an Apple Vision Pro with the word 'hello' written across the front in cursive.",
      "identifier": "visionOS-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/90294957b44e5508a55fe39373eea478/visionOS-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/90fe463571fd45badfabacbb07f30591/visionOS-PageImage-card~dark@2x.png"
        }
      ]
    }
  },
  "sampleCodeDownload": {
    "action": {
      "identifier": "c52a77b613db/ObjectPlacementExample.zip",
      "isActive": true,
      "overridingTitle": "Download",
      "type": "reference"
    },
    "kind": "sampleDownload"
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "ARKit",
      "generated": true,
      "identifiers": [
        "doc://com.apple.visionOS/documentation/visionOS/happybeam",
        "doc://com.apple.visionOS/documentation/visionOS/setting-up-access-to-arkit-data",
        "doc://com.apple.visionOS/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience",
        "doc://com.apple.visionOS/documentation/visionOS/tracking-points-in-world-space",
        "doc://com.apple.visionOS/documentation/visionOS/tracking-images-in-3d-space",
        "doc://com.apple.visionOS/documentation/visionOS/exploring_object_tracking_with_arkit",
        "doc://com.apple.visionOS/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences",
        "doc://com.apple.visionOS/documentation/visionOS/building_local_experiences_with_room_tracking",
        "doc://com.apple.visionOS/documentation/visionOS/placing-entities-using-head-and-device-transform"
      ],
      "title": "ARKit"
    }
  ]
}
