{
  "abstract": [
    {
      "text": "Find and track real-world objects in visionOS using reference objects trained with Create ML.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.visionOS/documentation/visionOS"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.visionOS/documentation/visionOS/exploring_object_tracking_with_arkit"
  },
  "kind": "article",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "images": [
      {
        "identifier": "Object-Tracking-PageImage-card.png",
        "type": "card"
      }
    ],
    "platforms": [
      {
        "beta": false,
        "introducedAt": "2.0",
        "name": "visionOS"
      },
      {
        "beta": false,
        "introducedAt": "16.0",
        "name": "Xcode"
      }
    ],
    "role": "sampleCode",
    "roleHeading": "Sample Code",
    "title": "Exploring object tracking with ARKit"
  },
  "primaryContentSections": [
    {
      "content": [
        {
          "anchor": "Overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "The sample app demonstrates how to use a reference object to discover and track a specific object in a person’s surroundings in visionOS. This capability allows you to create engaging experiences based on objects in a person’s surroundings and lets you  attach digital content to these objects. For example, you can build an app that uses reference objects to describe the specific assembly of a machine a person is testing or repairing. Using this reference model, when ARKit recognizes that object, you can attach digital content to it, such as a diagram of the device, more information about its function, and so on.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "This sample includes a reference object that ARKit uses to recognize a Magic Keyboard in someone’s surroundings.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "This sample code project is associated with WWDC24 ",
                  "type": "text"
                },
                {
                  "identifier": "https://developer.apple.com/wwdc24/10101/",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": ".",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        },
        {
          "anchor": "Configure-the-sample-code-project",
          "level": 2,
          "text": "Configure the sample code project",
          "type": "heading"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "This app requires Xcode 16 and visionOS 2 or later, and an Apple Vision Pro. Object tracking isn’t supported in the visionOS simulator.",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Note",
          "style": "note",
          "type": "aside"
        },
        {
          "items": [
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "In the project’s settings, select Signing and Capabilities.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Select your team name from the drop-down menu.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Pair Xcode with your device wirelessly or using the developer strap.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            },
            {
              "content": [
                {
                  "inlineContent": [
                    {
                      "text": "Click Run or press Command-R to launch the app.",
                      "type": "text"
                    }
                  ],
                  "type": "paragraph"
                }
              ]
            }
          ],
          "type": "orderedList"
        },
        {
          "anchor": "Import-the-reference-object-to-track-a-specific-object",
          "level": 2,
          "text": "Import the reference object to track a specific object",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Object tracking demonstrates two methods for importing a reference object into the app. The first loads reference objects directly from the app’s bundle, as shown here:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "func loadBuiltInReferenceObjects() async {",
            "    // Only allow one loading operation at any given time.",
            "    guard !didStartLoading else { return }",
            "    didStartLoading.toggle()",
            "    ",
            "    print(\"Looking for reference objects in the main bundle ...\")",
            "",
            "    // Get a list of all reference object files in the app's main bundle and attempt to load each.",
            "    var referenceObjectFiles: [String] = []",
            "    if let resourcesPath = Bundle.main.resourcePath {",
            "        try? referenceObjectFiles = FileManager.default.contentsOfDirectory(atPath: resourcesPath).filter { $0.hasSuffix(\".referenceobject\") }",
            "    }",
            "    ",
            "    fileCount = referenceObjectFiles.count",
            "    updateProgress()",
            "    ",
            "    await withTaskGroup(of: Void.self) { group in",
            "        for file in referenceObjectFiles {",
            "            let objectURL = Bundle.main.bundleURL.appending(path: file)",
            "            group.addTask {",
            "                await self.loadReferenceObject(objectURL)",
            "                await self.finishedOneFile()",
            "            }",
            "        }",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "In the second method, a person can provide a URL for a reference object file through a file importer dialog:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            ".fileImporter(isPresented: $fileImporterIsOpen, allowedContentTypes: [referenceObjectUTType], allowsMultipleSelection: true) { results in",
            "    switch results {",
            "    case .success(let fileURLs):",
            "        Task {",
            "            // Try to load each selected file as a reference object.",
            "            for fileURL in fileURLs {",
            "                guard fileURL.startAccessingSecurityScopedResource() else {",
            "                    print(\"Failed to get sandboxed access to the file \\(fileURL)\")",
            "                    return",
            "                }",
            "                await appState.referenceObjectLoader.addReferenceObject(fileURL)",
            "                fileURL.stopAccessingSecurityScopedResource()",
            "            }",
            "        }",
            "    case .failure(let error):",
            "        print(\"Failed to open file with error: \\(error)\")",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "anchor": "Run-object-tracking-on-a-session",
          "level": 2,
          "text": "Run object tracking on a session",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "To start receiving events, create an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/ObjectTrackingProvider",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " that you initialize with a reference object, and then start an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/ARKit/ARKitSession",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " with the ",
              "type": "text"
            },
            {
              "code": "ObjectTrackingProvider",
              "type": "codeVoice"
            },
            {
              "text": " you created, as shown below:",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "func startTracking() async -> ObjectTrackingProvider? {",
            "    let referenceObjects = referenceObjectLoader.enabledReferenceObjects",
            "    ",
            "    guard !referenceObjects.isEmpty else {",
            "        fatalError(\"No reference objects to start tracking\")",
            "    }",
            "    ",
            "    // Run a new provider every time when entering the immersive space.",
            "    let objectTracking = ObjectTrackingProvider(referenceObjects: referenceObjects)",
            "    do {",
            "        try await arkitSession.run([objectTracking])",
            "    } catch {",
            "        print(\"Error: \\(error)\" )",
            "        return nil",
            "    }",
            "    self.objectTracking = objectTracking",
            "    return objectTracking",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "anchor": "Handle-adding-updating-removing-and-visualizing-objects",
          "level": 2,
          "text": "Handle adding, updating, removing, and visualizing objects",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "ARKit delivers an asynchronous stream of updates as it detects changes in the scene. Your app needs to process these as they arrive and update the scene in response. The example below demonstrates handling these events inside the app’s ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/RealityKit/RealityView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ":",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "Task {",
            "    let objectTracking = await appState.startTracking()",
            "    guard let objectTracking else {",
            "        return",
            "    }",
            "    ",
            "    // Wait for object anchor updates and maintain a dictionary of visualizations",
            "    // that are attached to those anchors.",
            "    for await anchorUpdate in objectTracking.anchorUpdates {",
            "        let anchor = anchorUpdate.anchor",
            "        let id = anchor.id",
            "        ",
            "        switch anchorUpdate.event {",
            "        case .added:",
            "            // Create a new visualization for the reference object that ARKit just detected.",
            "            // The app displays the USDZ file that the reference object was trained on as",
            "            // a wireframe on top of the real-world object, if the .referenceobject file contains",
            "            // that USDZ file. If the original USDZ isn't available, the app displays a bounding box instead.",
            "            let model = appState.referenceObjectLoader.usdzsPerReferenceObjectID[anchor.referenceObject.id]",
            "            let visualization = ObjectAnchorVisualization(for: anchor, withModel: model)",
            "            self.objectVisualizations[id] = visualization",
            "            root.addChild(visualization.entity)",
            "        case .updated:",
            "            objectVisualizations[id]?.update(with: anchor)",
            "        case .removed:",
            "            objectVisualizations[id]?.entity.removeFromParent()",
            "            objectVisualizations.removeValue(forKey: id)",
            "        }",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "When the app adds objects to the scene, it attaches virtual content to the reference object using the ",
              "type": "text"
            },
            {
              "code": "ObjectAnchorVisualization",
              "type": "codeVoice"
            },
            {
              "text": " entity to render a wireframe that shows the reference object’s outline.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Create-your-own-reference-objects",
          "level": 2,
          "text": "Create your own reference objects",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Creating your own reference objects requires an iPhone, iPad, or other device that you can use to create high-fidelity scans of the physical object you want to model, and a Mac with an M2 chip or later to process the images and create a reference object using Create ML.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "66b7ac751448/ExploringObjectTrackingWithARKit.zip": {
      "checksum": "66b7ac75144854b13c98c7cafe612aebe2779390085e9a1b19b3118b9c5707abb0e2419a7b9105e4ba142c8c2db73752cce999266f0b6ed4671ba875fa8b6586",
      "identifier": "66b7ac751448/ExploringObjectTrackingWithARKit.zip",
      "type": "download",
      "url": "https://docs-assets.developer.apple.com/published/66b7ac751448/ExploringObjectTrackingWithARKit.zip"
    },
    "Building-local-experiences-with-room-tracking-PageImage-card.png": {
      "alt": "A view into the corner of a room with an open doorway, where one wall is a portal to a virtual universe.",
      "identifier": "Building-local-experiences-with-room-tracking-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/ecb2f88d37f7bba036c739568409febf/Building-local-experiences-with-room-tracking-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/af99ba5e2e307907caed07d89553f518/Building-local-experiences-with-room-tracking-PageImage-card~dark@2x.png"
        }
      ]
    },
    "Happy-Beam-intro.png": {
      "alt": "A screenshot showing the Happy Beam game. A player makes a heart gesture with their hands, a beam projects from it aimed at nearby clouds, and a scoreboard window shows seven points.",
      "identifier": "Happy-Beam-intro.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/52b497b6d705af322726d7371dee6ddd/Happy-Beam-intro@2x.png"
        }
      ]
    },
    "Object-Tracking-PageImage-card.png": {
      "alt": null,
      "identifier": "Object-Tracking-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/dfd3696d1b7df884ded8407cef3e8045/Object-Tracking-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/2332d74827799a86de0261e14c5a61f5/Object-Tracking-PageImage-card~dark@2x.png"
        }
      ]
    },
    "doc://com.apple.documentation/documentation/ARKit/ARKitSession": {
      "abstract": [
        {
          "text": "The main entry point for receiving data from ARKit.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "final"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ARKitSession"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/ARKitSession",
      "kind": "symbol",
      "role": "symbol",
      "title": "ARKitSession",
      "type": "topic",
      "url": "/documentation/ARKit/ARKitSession"
    },
    "doc://com.apple.documentation/documentation/ARKit/ObjectTrackingProvider": {
      "abstract": [
        {
          "text": "A source of real-time position of reference objects in a person’s environment.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "final"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ObjectTrackingProvider"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/ARKit/ObjectTrackingProvider",
      "kind": "symbol",
      "role": "symbol",
      "title": "ObjectTrackingProvider",
      "type": "topic",
      "url": "/documentation/ARKit/ObjectTrackingProvider"
    },
    "doc://com.apple.documentation/documentation/RealityKit/RealityView": {
      "abstract": [
        {
          "text": "A view that contains RealityKit content.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "attribute",
          "text": "@"
        },
        {
          "kind": "attribute",
          "preciseIdentifier": "s:ScM",
          "text": "MainActor"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "attribute",
          "text": "@preconcurrency"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "RealityView"
        },
        {
          "kind": "text",
          "text": "<"
        },
        {
          "kind": "genericParameter",
          "text": "Content"
        },
        {
          "kind": "text",
          "text": "> "
        },
        {
          "kind": "keyword",
          "text": "where"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "typeIdentifier",
          "text": "Content"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:7SwiftUI4ViewP",
          "text": "View"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/RealityKit/RealityView",
      "kind": "symbol",
      "role": "symbol",
      "title": "RealityView",
      "type": "topic",
      "url": "/documentation/RealityKit/RealityView"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "doc://com.apple.visionOS/documentation/visionOS": {
      "abstract": [
        {
          "text": "Create a new universe of apps and games for Apple Vision Pro.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS",
      "images": [
        {
          "identifier": "headset-orange.svg",
          "type": "icon"
        },
        {
          "identifier": "visionOS-PageImage-card.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "collection",
      "title": "visionOS",
      "type": "topic",
      "url": "/documentation/visionos"
    },
    "doc://com.apple.visionOS/documentation/visionOS/building_local_experiences_with_room_tracking": {
      "abstract": [
        {
          "text": "Use room tracking in visionOS to provide custom interactions with physical spaces.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/building_local_experiences_with_room_tracking",
      "images": [
        {
          "identifier": "Building-local-experiences-with-room-tracking-PageImage-card.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "sampleCode",
      "title": "Building local experiences with room tracking",
      "type": "topic",
      "url": "/documentation/visionos/building_local_experiences_with_room_tracking"
    },
    "doc://com.apple.visionOS/documentation/visionOS/happybeam": {
      "abstract": [
        {
          "text": "Leverage a Full Space to create a fun game using ARKit.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/happybeam",
      "images": [
        {
          "identifier": "Happy-Beam-intro.png",
          "type": "card"
        }
      ],
      "kind": "article",
      "role": "sampleCode",
      "title": "Happy Beam",
      "type": "topic",
      "url": "/documentation/visionos/happybeam"
    },
    "doc://com.apple.visionOS/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience": {
      "abstract": [
        {
          "text": "Create an immersive experience by making your app’s content respond to the local shape of the world.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience",
      "kind": "article",
      "role": "sampleCode",
      "title": "Incorporating real-world surroundings in an immersive experience",
      "type": "topic",
      "url": "/documentation/visionos/incorporating-real-world-surroundings-in-an-immersive-experience"
    },
    "doc://com.apple.visionOS/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences": {
      "abstract": [
        {
          "text": "Use object tracking in visionOS to attach digital content to real objects to create engaging experiences.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences",
      "kind": "article",
      "role": "sampleCode",
      "title": "Object tracking with Reality Composer Pro experiences",
      "type": "topic",
      "url": "/documentation/visionos/object-tracking-with-reality-composer-pro-experiences"
    },
    "doc://com.apple.visionOS/documentation/visionOS/placing-content-on-detected-planes": {
      "abstract": [
        {
          "text": "Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/placing-content-on-detected-planes",
      "kind": "article",
      "role": "sampleCode",
      "title": "Placing content on detected planes",
      "type": "topic",
      "url": "/documentation/visionos/placing-content-on-detected-planes"
    },
    "doc://com.apple.visionOS/documentation/visionOS/placing-entities-using-head-and-device-transform": {
      "abstract": [
        {
          "text": "Query and react to changes in the position and rotation of Apple Vision Pro.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/placing-entities-using-head-and-device-transform",
      "kind": "article",
      "role": "sampleCode",
      "title": "Placing entities using head and device transform",
      "type": "topic",
      "url": "/documentation/visionos/placing-entities-using-head-and-device-transform"
    },
    "doc://com.apple.visionOS/documentation/visionOS/setting-up-access-to-arkit-data": {
      "abstract": [
        {
          "text": "Check whether your app can use ARKit and respect people’s privacy.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/setting-up-access-to-arkit-data",
      "kind": "article",
      "role": "article",
      "title": "Setting up access to ARKit data",
      "type": "topic",
      "url": "/documentation/visionos/setting-up-access-to-arkit-data"
    },
    "doc://com.apple.visionOS/documentation/visionOS/tracking-images-in-3d-space": {
      "abstract": [
        {
          "text": "Place content based on the current position of a known image in a person’s surroundings.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/tracking-images-in-3d-space",
      "kind": "article",
      "role": "article",
      "title": "Tracking preregistered images in 3D space",
      "type": "topic",
      "url": "/documentation/visionos/tracking-images-in-3d-space"
    },
    "doc://com.apple.visionOS/documentation/visionOS/tracking-points-in-world-space": {
      "abstract": [
        {
          "text": "Retrieve the position and orientation of anchors your app stores in ARKit.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.visionOS/documentation/visionOS/tracking-points-in-world-space",
      "kind": "article",
      "role": "sampleCode",
      "title": "Tracking specific points in world space",
      "type": "topic",
      "url": "/documentation/visionos/tracking-points-in-world-space"
    },
    "headset-orange.svg": {
      "alt": "An icon representing visionOS.",
      "identifier": "headset-orange.svg",
      "type": "image",
      "variants": [
        {
          "svgID": "a",
          "traits": [
            "1x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/77dc6a0821bfb2da8db4a3b2033e6f6b/headset-orange.svg"
        }
      ]
    },
    "https://developer.apple.com/wwdc24/10101/": {
      "identifier": "https://developer.apple.com/wwdc24/10101/",
      "title": "Session 10101 — Explore object tracking for visionOS",
      "titleInlineContent": [
        {
          "text": "Session 10101 — Explore object tracking for visionOS",
          "type": "text"
        }
      ],
      "type": "link",
      "url": "https://developer.apple.com/wwdc24/10101/"
    },
    "visionOS-PageImage-card.png": {
      "alt": "A stylized illustration of an Apple Vision Pro with the word 'hello' written across the front in cursive.",
      "identifier": "visionOS-PageImage-card.png",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/90294957b44e5508a55fe39373eea478/visionOS-PageImage-card@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/90fe463571fd45badfabacbb07f30591/visionOS-PageImage-card~dark@2x.png"
        }
      ]
    }
  },
  "sampleCodeDownload": {
    "action": {
      "identifier": "66b7ac751448/ExploringObjectTrackingWithARKit.zip",
      "isActive": true,
      "overridingTitle": "Download",
      "type": "reference"
    },
    "kind": "sampleDownload"
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "ARKit",
      "generated": true,
      "identifiers": [
        "doc://com.apple.visionOS/documentation/visionOS/happybeam",
        "doc://com.apple.visionOS/documentation/visionOS/setting-up-access-to-arkit-data",
        "doc://com.apple.visionOS/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience",
        "doc://com.apple.visionOS/documentation/visionOS/placing-content-on-detected-planes",
        "doc://com.apple.visionOS/documentation/visionOS/tracking-points-in-world-space",
        "doc://com.apple.visionOS/documentation/visionOS/tracking-images-in-3d-space",
        "doc://com.apple.visionOS/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences",
        "doc://com.apple.visionOS/documentation/visionOS/building_local_experiences_with_room_tracking",
        "doc://com.apple.visionOS/documentation/visionOS/placing-entities-using-head-and-device-transform"
      ],
      "title": "ARKit"
    }
  ]
}
