{
  "abstract": [
    {
      "text": "Add a Live Text interface that enables users to perform actions with text and QR",
      "type": "text"
    },
    {
      "text": " ",
      "type": "text"
    },
    {
      "text": "codes that appear in images.",
      "type": "text"
    }
  ],
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.VisionKit/documentation/VisionKit"
      ]
    ]
  },
  "identifier": {
    "interfaceLanguage": "swift",
    "url": "doc://com.apple.VisionKit/documentation/VisionKit/enabling-live-text-interactions-with-images"
  },
  "kind": "article",
  "legalNotices": {
    "copyright": "Copyright &copy; 2025 Apple Inc. All rights reserved.",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html"
  },
  "metadata": {
    "modules": [
      {
        "name": "VisionKit"
      }
    ],
    "role": "article",
    "roleHeading": "Article",
    "title": "Enabling Live Text interactions with images"
  },
  "primaryContentSections": [
    {
      "content": [
        {
          "anchor": "Overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Enhance the user experience with images in your app by adding standard Live Text",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "interactions. Live Text lets users tap text in an image to copy it, make a call,",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "send an email, translate it, or look up directions. VisionKit provides this familiar",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "Live Text interface to your images and across platforms.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "For iOS apps, users can use a long-press gesture (touch and hold) a QR code to follow",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "a link or take another action, depending on the payload. The payload is the data",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "that a QR code contains, such as a URL or email address.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Before interacting with items in an image, the user can tap the Live Text button",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "in the lower-right corner to highlight the recognized items. Then a data-specific",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "action menu appears when the user double-taps on text in an image, and uses a long-press",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "gesture on an email address or QR code.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "identifier": "enabling_live_text_interactions_with_images-1",
              "type": "image"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "In your app, you decide whether Live Text recognizes text and data within text, and",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "for iOS apps, QR codes in the image. You choose the types of items to look for and",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "run the analysis on the image, and then VisionKit provides the entire Live Text interface",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "with the breadth of actions for specific types.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "content": [
            {
              "inlineContent": [
                {
                  "text": "The code listings in this article use asynchronous methods that you",
                  "type": "text"
                },
                {
                  "text": " ",
                  "type": "text"
                },
                {
                  "text": "invoke from an ",
                  "type": "text"
                },
                {
                  "code": "async",
                  "type": "codeVoice"
                },
                {
                  "text": " method or within a ",
                  "type": "text"
                },
                {
                  "identifier": "doc://com.apple.documentation/documentation/Swift/Task",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": " ",
                  "type": "text"
                },
                {
                  "text": "structure. For details on asynchronous flows, see ",
                  "type": "text"
                },
                {
                  "identifier": "doc://com.apple.documentation/documentation/Swift/concurrency",
                  "isActive": true,
                  "type": "reference"
                },
                {
                  "text": ".",
                  "type": "text"
                }
              ],
              "type": "paragraph"
            }
          ],
          "name": "Important",
          "style": "important",
          "type": "aside"
        },
        {
          "anchor": "Check-whether-the-device-supports-Live-Text",
          "level": 3,
          "text": "Check whether the device supports Live Text",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Before showing a Live Text interface in your app, check whether the device supports",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "Live Text. For iOS apps, the image analyzer is available only on devices with the",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "A12 Bionic chip and later. If the ",
              "type": "text"
            },
            {
              "code": "ImageAnalyzer",
              "type": "codeVoice"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/isSupported",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property is ",
              "type": "text"
            },
            {
              "code": "true",
              "type": "codeVoice"
            },
            {
              "text": ", show the",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "Live Text interface. Otherwise, disable any feature in your app that relies on Live",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "Text. If you attempt to start the Live Text interface when this property is ",
              "type": "text"
            },
            {
              "code": "false",
              "type": "codeVoice"
            },
            {
              "text": ",",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the interface doesn’t appear.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Add-a-Live-Text-interaction-object-to-your-view-in-iOS",
          "level": 3,
          "text": "Add a Live Text interaction object to your view in iOS",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "For iOS apps, you add the Live Text interface by adding an interaction object to",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the view containing the image. If you use a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/UIKit/UIImageView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to display the image, it handles the image content area calculations for you.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "Add an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object directly on the view containing",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the image.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "let interaction = ImageAnalysisInteraction()",
            "imageView.addInteraction(interaction)"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "Optionally, customize the interface by setting the interaction’s delegate to an object",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "that implements the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " protocol methods.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "interaction.delegate = self"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "If you don’t use a ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/UIKit/UIImageView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "object, inform the interaction object when the content area of the image changes",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "while the interaction bounds don’t change. Implement the ",
              "type": "text"
            },
            {
              "code": "ImageAnalysisInteractionDelegate",
              "type": "codeVoice"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate/contentsRect(for:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " protocol method",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to return the content area of the image. This keeps the Live Text highlights within",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the bounds of the image. Then use the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/setContentsRectNeedsUpdate()",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "method to notify the interaction if the content area changes.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Add-a-Live-Text-view-to-your-image-view-in-macOS",
          "level": 3,
          "text": "Add a Live Text view to your image view in macOS",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "For macOS apps, add the Live Text interface by adding a view above the view containing",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the image. If you use an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AppKit/NSImageView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to display the image, it handles the image content area calculations for you.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "First create an instance of the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " class.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "let overlayView = ImageAnalysisOverlayView()"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "Then configure the overlay view to fit the bounds of the image. If your view is an",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "image view, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/trackingImageView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " property",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "so that the dimensions adjust when the scaling and alignment properties change.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "overlayView.autoresizingMask = [.width, .height]",
            "overlayView.frame = imageView.bounds",
            "overlayView.trackingImageView = imageView"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "Add the overlay view above the image in the hierarchy. For example, add it as a subview",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "of the view containing the image.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "imageView.addSubview(overlayView)"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "To customize the interface, set the overlay view’s delegate to an object that implements",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the optional ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " protocol methods.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "overlayView.delegate = self"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "Implement the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate/overlayView(_:shouldBeginAt:forAnalysisType:)-35czq",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "protocol method to return ",
              "type": "text"
            },
            {
              "code": "true",
              "type": "codeVoice"
            },
            {
              "text": " to begin the interaction.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "func overlayView(_ overlayView: ImageAnalysisOverlayView, ",
            "           shouldBeginAt point: CGPoint, forAnalysisType ",
            "           analysisType: ImageAnalysisOverlayView.InteractionTypes) -> Bool { ",
            "    overlayView.hasInteractiveItem(at: point) || ",
            "    overlayView.hasActiveTextSelection ",
            "}"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "If you aren’t using an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/AppKit/NSImageView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "object, implement the ",
              "type": "text"
            },
            {
              "code": "ImageAnalysisOverlayViewDelegate",
              "type": "codeVoice"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate/contentsRect(for:)-34yzu",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "protocol method to return the content area of the image. Then use the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/setContentsRectNeedsUpdate()",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "method to notify the overlay view if the content area of the image changes while",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the view bounds don’t change.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "identifier": "enabling_live_text_interactions_with_images-2",
              "type": "image"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Find-items-and-start-the-interaction-with-an-image",
          "level": 3,
          "text": "Find items and start the interaction with an image",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "Process the image that your view displays using an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object.",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "First, specify the types of items in the image you want to find when you create an",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object. For iOS apps, the analyzer recognizes",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "both text and machine-readable QR codes in an image; for macOS apps, the analyzer",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "recognizes text in an image.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "let configuration = ImageAnalyzer.Configuration([.text, .machineReadableCode])"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "Then analyze the image by sending ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/analyze(_:configuration:)",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to an ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object, passing the image and the configuration.",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "To improve performance, use a single shared instance of the analyzer throughout the",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "app.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "let analyzer = ImageAnalyzer()",
            "let analysis = try? await analyzer.analyze(image, configuration: configuration)"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "For iOS apps, start the Live Text interface by setting the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/analysis",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property of the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object to the results of the",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "analyze method. For example, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/analysis",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property in the action method of a control that starts Live Text.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "interaction.analysis = analysis"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "For macOS apps, start the Live Text interface by setting the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/analysis",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property of the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "overlayView.analysis = analysis"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "The standard Live Text menu appears when users click and hold items in the image.",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "The user chooses actions from this menu, depending on the type of item.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Customize-behavior-using-interaction-types",
          "level": 3,
          "text": "Customize behavior using interaction types",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "You can change the behavior of the interface by enabling types of interactions with",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "items the analyzer finds in the image. If you set the interaction or overlay view",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/preferredInteractionTypes",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " property to ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/InteractionTypes/automatic",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ",",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "users can interact with all types of items that the analyzer finds.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "code": [
            "interaction.preferredInteractionTypes = .automatic"
          ],
          "syntax": "swift",
          "type": "codeListing"
        },
        {
          "inlineContent": [
            {
              "text": "If you set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/preferredInteractionTypes",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " property",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to just ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/InteractionTypes/textSelection",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ", users",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "can only select text in the image and then perform a basic text action, such as copying,",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "translating, or sharing the text. For iOS apps, if the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "object’s ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/allowLongPressForDataDetectorsInTextMode",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property is ",
              "type": "text"
            },
            {
              "code": "true",
              "type": "codeVoice"
            },
            {
              "text": ", users can also touch and hold text that contains data (URLs,",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "phone numbers, and email addresses) to perform a data-specific action.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "For iOS apps, users can tap the Live Text button in the lower-right corner to switch",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to highlight mode. Then users can touch and hold data that the analyzer detects in",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "text to perform a data-specific action, such as opening a URL, calling a phone number,",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "or sending an email.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "identifier": "enabling_live_text_interactions_with_images-3",
              "type": "image"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "To let users interact with data that the analyzer detects in text in macOS, set the",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/preferredInteractionTypes",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " property to ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/InteractionTypes/dataDetectors",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "Then users can hover over data in text to perform a data-specific action.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "For iOS apps only, users can touch and hold QR codes and perform an action, depending",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "on the payload, such as following an embedded link. To enable QR code interactions,",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " structure’s ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration/analysisTypes",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property to ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/AnalysisTypes/machineReadableCode",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Change-the-supplementary-interface",
          "level": 3,
          "text": "Change the supplementary interface",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "You can modify the Live Text supplementary interface to conform better to the look",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "of your app. The supplementary interface consists of the quick actions in the lower-left",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "corner and the Live Text button in the lower-right corner of the interface.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "To hide the supplementary interface, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/isSupplementaryInterfaceHidden",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "to ",
              "type": "text"
            },
            {
              "code": "false",
              "type": "codeVoice"
            },
            {
              "text": ". For iOS apps, if",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/allowLongPressForDataDetectorsInTextMode",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property is ",
              "type": "text"
            },
            {
              "code": "true",
              "type": "codeVoice"
            },
            {
              "text": ", users can",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "still touch and hold text to perform data-specific actions.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "If your interface overlaps the supplementary interface, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/supplementaryInterfaceContentInsets",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property appropriately to move the quick actions and Live Text button.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "If you want the supplementary interface to use a custom font, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/supplementaryInterfaceFont",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property. Quick actions use the specified font for text and font weight for symbols.",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "For button size consistency, the Live Text interface ignores the point size.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "anchor": "Specify-recognized-languages",
          "level": 3,
          "text": "Specify recognized languages",
          "type": "heading"
        },
        {
          "inlineContent": [
            {
              "text": "By default the image analyzer attempts to recognize the user’s preferred languages.",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "If you want the analyzer to consider other languages, set the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration/locales",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "property of the ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " object.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "To determine whether the image analyzer supports a language, check whether the array",
              "type": "text"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "that the ",
              "type": "text"
            },
            {
              "code": "ImageAnalyzer",
              "type": "codeVoice"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/supportedTextRecognitionLanguages",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": " ",
              "type": "text"
            },
            {
              "text": "class property returns includes the language ID.",
              "type": "text"
            }
          ],
          "type": "paragraph"
        },
        {
          "inlineContent": [
            {
              "text": "For more information on language IDs, see ",
              "type": "text"
            },
            {
              "identifier": "doc://com.apple.documentation/documentation/Xcode/choosing-localization-regions-and-scripts",
              "isActive": true,
              "type": "reference"
            },
            {
              "text": ".",
              "type": "text"
            }
          ],
          "type": "paragraph"
        }
      ],
      "kind": "content"
    }
  ],
  "references": {
    "doc://com.apple.VisionKit/documentation/VisionKit": {
      "abstract": [
        {
          "text": "Identify and extract information in the environment using the device’s camera, or in images that your app displays.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit",
      "kind": "symbol",
      "role": "collection",
      "title": "VisionKit",
      "type": "topic",
      "url": "/documentation/visionkit"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysis": {
      "abstract": [
        {
          "text": "An object that represents the results of analyzing an image, and provides",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "the input for the Live Text interface object.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAnalysis"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysis",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAnalysis"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalysis",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysis"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction": {
      "abstract": [
        {
          "text": "An interface that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAnalysisInteraction"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAnalysisInteraction"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalysisInteraction",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/InteractionTypes/automatic": {
      "abstract": [
        {
          "text": "An option that enables interaction with any type of text, symbols, or subjects that the framework recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "automatic"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisInteraction",
          "text": "ImageAnalysisInteraction"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit24ImageAnalysisInteractionC0E5TypesV",
          "text": "InteractionTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/InteractionTypes/automatic",
      "kind": "symbol",
      "role": "symbol",
      "title": "automatic",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/interactiontypes/automatic"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/InteractionTypes/textSelection": {
      "abstract": [
        {
          "text": "An option that enables text selection, copying, and translating.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "textSelection"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisInteraction",
          "text": "ImageAnalysisInteraction"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit24ImageAnalysisInteractionC0E5TypesV",
          "text": "InteractionTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/InteractionTypes/textSelection",
      "kind": "symbol",
      "role": "symbol",
      "title": "textSelection",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/interactiontypes/textselection"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/allowLongPressForDataDetectorsInTextMode": {
      "abstract": [
        {
          "text": "A Boolean value that indicates whether people can press and hold text to",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "activate data detectors.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "allowLongPressForDataDetectorsInTextMode"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Sb",
          "text": "Bool"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/allowLongPressForDataDetectorsInTextMode",
      "kind": "symbol",
      "role": "symbol",
      "title": "allowLongPressForDataDetectorsInTextMode",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/allowlongpressfordatadetectorsintextmode"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/analysis": {
      "abstract": [
        {
          "text": "The results of analyzing an image for items that people can interact",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "with.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "analysis"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalysisC",
          "text": "ImageAnalysis"
        },
        {
          "kind": "text",
          "text": "?"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/analysis",
      "kind": "symbol",
      "role": "symbol",
      "title": "analysis",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/analysis"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/isSupplementaryInterfaceHidden": {
      "abstract": [
        {
          "text": "A Boolean value that indicates whether the view hides supplementary",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "interface objects.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "isSupplementaryInterfaceHidden"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Sb",
          "text": "Bool"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/isSupplementaryInterfaceHidden",
      "kind": "symbol",
      "role": "symbol",
      "title": "isSupplementaryInterfaceHidden",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/issupplementaryinterfacehidden"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/preferredInteractionTypes": {
      "abstract": [
        {
          "text": "The types of interactions that people can perform with the image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "preferredInteractionTypes"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisInteraction",
          "text": "ImageAnalysisInteraction"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit24ImageAnalysisInteractionC0E5TypesV",
          "text": "InteractionTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/preferredInteractionTypes",
      "kind": "symbol",
      "role": "symbol",
      "title": "preferredInteractionTypes",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/preferredinteractiontypes"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/setContentsRectNeedsUpdate()": {
      "abstract": [
        {
          "text": "Informs the view that contains the image when the layout changes and the",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "view needs to reload its content.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "setContentsRectNeedsUpdate"
        },
        {
          "kind": "text",
          "text": "()"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/setContentsRectNeedsUpdate()",
      "kind": "symbol",
      "role": "symbol",
      "title": "setContentsRectNeedsUpdate()",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/setcontentsrectneedsupdate()"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/supplementaryInterfaceContentInsets": {
      "abstract": [
        {
          "text": "The distances the edges of content are inset from the supplementary",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "interface.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supplementaryInterfaceContentInsets"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@UIEdgeInsets",
          "text": "UIEdgeInsets"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/supplementaryInterfaceContentInsets",
      "kind": "symbol",
      "role": "symbol",
      "title": "supplementaryInterfaceContentInsets",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/supplementaryinterfacecontentinsets"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/supplementaryInterfaceFont": {
      "abstract": [
        {
          "text": "The font to use for the supplementary interface.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supplementaryInterfaceFont"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)UIFont",
          "text": "UIFont"
        },
        {
          "kind": "text",
          "text": "?"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction/supplementaryInterfaceFont",
      "kind": "symbol",
      "role": "symbol",
      "title": "supplementaryInterfaceFont",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteraction/supplementaryinterfacefont"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate": {
      "abstract": [
        {
          "text": "A delegate that handles image-analysis and user-interaction callbacks for an interaction object.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAnalysisInteractionDelegate"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAnalysisInteractionDelegate"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalysisInteractionDelegate",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteractiondelegate"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate/contentsRect(for:)": {
      "abstract": [
        {
          "text": "Returns the rectangle, in unit coordinates, that contains the image within the view.",
          "type": "text"
        }
      ],
      "defaultImplementations": 1,
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "contentsRect"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "for"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisInteraction",
          "text": "ImageAnalysisInteraction"
        },
        {
          "kind": "text",
          "text": ") -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@CGRect",
          "text": "CGRect"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate/contentsRect(for:)",
      "kind": "symbol",
      "required": true,
      "role": "symbol",
      "title": "contentsRect(for:)",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisinteractiondelegate/contentsrect(for:)"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView": {
      "abstract": [
        {
          "text": "A view that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAnalysisOverlayView"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAnalysisOverlayView"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalysisOverlayView",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayview"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/InteractionTypes/dataDetectors": {
      "abstract": [
        {
          "text": "An option that enables interaction with text of certain formats,",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "such as URLs, email addresses, and physical addresses.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "dataDetectors"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisOverlayView",
          "text": "ImageAnalysisOverlayView"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit24ImageAnalysisOverlayViewC16InteractionTypesV",
          "text": "InteractionTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/InteractionTypes/dataDetectors",
      "kind": "symbol",
      "role": "symbol",
      "title": "dataDetectors",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayview/interactiontypes/datadetectors"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/analysis": {
      "abstract": [
        {
          "text": "The results of analyzing an image for items that people can interact with.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "analysis"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalysisC",
          "text": "ImageAnalysis"
        },
        {
          "kind": "text",
          "text": "?"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/analysis",
      "kind": "symbol",
      "role": "symbol",
      "title": "analysis",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayview/analysis"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/preferredInteractionTypes": {
      "abstract": [
        {
          "text": "The types of interactions that people can perform with the image in this overlay view.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "preferredInteractionTypes"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisOverlayView",
          "text": "ImageAnalysisOverlayView"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit24ImageAnalysisOverlayViewC16InteractionTypesV",
          "text": "InteractionTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/preferredInteractionTypes",
      "kind": "symbol",
      "role": "symbol",
      "title": "preferredInteractionTypes",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayview/preferredinteractiontypes"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/setContentsRectNeedsUpdate()": {
      "abstract": [
        {
          "text": "Informs the view that contains the image when the layout changes and the view needs to reload its content.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "setContentsRectNeedsUpdate"
        },
        {
          "kind": "text",
          "text": "()"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/setContentsRectNeedsUpdate()",
      "kind": "symbol",
      "role": "symbol",
      "title": "setContentsRectNeedsUpdate()",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayview/setcontentsrectneedsupdate()"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/trackingImageView": {
      "abstract": [
        {
          "text": "The image view that contains the image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "trackingImageView"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)NSImageView",
          "text": "NSImageView"
        },
        {
          "kind": "text",
          "text": "?"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView/trackingImageView",
      "kind": "symbol",
      "role": "symbol",
      "title": "trackingImageView",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayview/trackingimageview"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate": {
      "abstract": [
        {
          "text": "A delegate that handles image-analysis and user-interaction callbacks for an overlay view.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "protocol"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAnalysisOverlayViewDelegate"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAnalysisOverlayViewDelegate"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalysisOverlayViewDelegate",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayviewdelegate"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate/contentsRect(for:)-34yzu": {
      "abstract": [
        {
          "text": "A default implementation that returns a rectangle that specifies the full width and height of the view.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "contentsRect"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "externalParam",
          "text": "for"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisOverlayView",
          "text": "ImageAnalysisOverlayView"
        },
        {
          "kind": "text",
          "text": ") -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@CGRect",
          "text": "CGRect"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate/contentsRect(for:)-34yzu",
      "kind": "symbol",
      "role": "symbol",
      "title": "contentsRect(for:)",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayviewdelegate/contentsrect(for:)-34yzu"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate/overlayView(_:shouldBeginAt:forAnalysisType:)-35czq": {
      "abstract": [
        {
          "text": "Indicates whether interaction begins at the given point for the specified interaction type.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "overlayView"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisOverlayView",
          "text": "ImageAnalysisOverlayView"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "shouldBeginAt"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@S@CGPoint",
          "text": "CGPoint"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "forAnalysisType"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:@M@VisionKit@objc(cs)ImageAnalysisOverlayView",
          "text": "ImageAnalysisOverlayView"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit24ImageAnalysisOverlayViewC16InteractionTypesV",
          "text": "InteractionTypes"
        },
        {
          "kind": "text",
          "text": ") -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Sb",
          "text": "Bool"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate/overlayView(_:shouldBeginAt:forAnalysisType:)-35czq",
      "kind": "symbol",
      "role": "symbol",
      "title": "overlayView(_:shouldBeginAt:forAnalysisType:)",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalysisoverlayviewdelegate/overlayview(_:shouldbeginat:foranalysistype:)-35czq"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer": {
      "abstract": [
        {
          "text": "An object that finds items in images that people can interact with, such",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "as subjects, text, and QR codes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "ImageAnalyzer"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "ImageAnalyzer"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalyzer",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/AnalysisTypes/machineReadableCode": {
      "abstract": [
        {
          "text": "An option that analyzes an image for machine-readable codes, such as QR codes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "static"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "machineReadableCode"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalyzerC",
          "text": "ImageAnalyzer"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalyzerC13AnalysisTypesV",
          "text": "AnalysisTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/AnalysisTypes/machineReadableCode",
      "kind": "symbol",
      "role": "symbol",
      "title": "machineReadableCode",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/analysistypes/machinereadablecode"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration": {
      "abstract": [
        {
          "text": "A configuration that specifies the types of items and locales that the",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "image analyzer recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Configuration"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration",
      "kind": "symbol",
      "navigatorTitle": [
        {
          "kind": "identifier",
          "text": "Configuration"
        }
      ],
      "role": "symbol",
      "title": "ImageAnalyzer.Configuration",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/configuration"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration/analysisTypes": {
      "abstract": [
        {
          "text": "The types of items that the image analyzer looks for in the image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "let"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "analysisTypes"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalyzerC",
          "text": "ImageAnalyzer"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalyzerC13AnalysisTypesV",
          "text": "AnalysisTypes"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration/analysisTypes",
      "kind": "symbol",
      "role": "symbol",
      "title": "analysisTypes",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/configuration/analysistypes"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration/locales": {
      "abstract": [
        {
          "text": "The languages to use in text items that the image analyzer",
          "type": "text"
        },
        {
          "text": " ",
          "type": "text"
        },
        {
          "text": "recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "locales"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        },
        {
          "kind": "text",
          "text": "]"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/Configuration/locales",
      "kind": "symbol",
      "role": "symbol",
      "title": "locales",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/configuration/locales"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/analyze(_:configuration:)": {
      "abstract": [
        {
          "text": "Returns the data for providing a Live Text interaction with an image.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "func"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "analyze"
        },
        {
          "kind": "text",
          "text": "("
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "c:objc(cs)UIImage",
          "text": "UIImage"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "externalParam",
          "text": "configuration"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalyzerC",
          "text": "ImageAnalyzer"
        },
        {
          "kind": "text",
          "text": "."
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalyzerC13ConfigurationV",
          "text": "Configuration"
        },
        {
          "kind": "text",
          "text": ") "
        },
        {
          "kind": "keyword",
          "text": "async"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "throws"
        },
        {
          "kind": "text",
          "text": " -> "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:9VisionKit13ImageAnalysisC",
          "text": "ImageAnalysis"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/analyze(_:configuration:)",
      "kind": "symbol",
      "role": "symbol",
      "title": "analyze(_:configuration:)",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/analyze(_:configuration:)"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/isSupported": {
      "abstract": [
        {
          "text": "A Boolean value that indicates whether the device supports image analysis.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "isSupported"
        },
        {
          "kind": "text",
          "text": ": "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:Sb",
          "text": "Bool"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/isSupported",
      "kind": "symbol",
      "role": "symbol",
      "title": "isSupported",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/issupported"
    },
    "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/supportedTextRecognitionLanguages": {
      "abstract": [
        {
          "text": "The identifiers for the languages that the image analyzer recognizes.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "var"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "supportedTextRecognitionLanguages"
        },
        {
          "kind": "text",
          "text": ": ["
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:SS",
          "text": "String"
        },
        {
          "kind": "text",
          "text": "]"
        }
      ],
      "identifier": "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer/supportedTextRecognitionLanguages",
      "kind": "symbol",
      "role": "symbol",
      "title": "supportedTextRecognitionLanguages",
      "type": "topic",
      "url": "/documentation/visionkit/imageanalyzer/supportedtextrecognitionlanguages"
    },
    "doc://com.apple.documentation/documentation/AppKit/NSImageView": {
      "abstract": [
        {
          "text": "A display of image data in a frame.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "attribute",
          "text": "@"
        },
        {
          "kind": "attribute",
          "preciseIdentifier": "s:ScM",
          "text": "MainActor"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "NSImageView"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/AppKit/NSImageView",
      "kind": "symbol",
      "role": "symbol",
      "title": "NSImageView",
      "type": "topic",
      "url": "/documentation/AppKit/NSImageView"
    },
    "doc://com.apple.documentation/documentation/Swift/Task": {
      "abstract": [
        {
          "text": "A unit of asynchronous work.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "attribute",
          "text": "@frozen"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "struct"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "Task"
        },
        {
          "kind": "text",
          "text": "<"
        },
        {
          "kind": "genericParameter",
          "text": "Success"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "genericParameter",
          "text": "Failure"
        },
        {
          "kind": "text",
          "text": "> "
        },
        {
          "kind": "keyword",
          "text": "where"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "typeIdentifier",
          "text": "Success"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:s8SendableP",
          "text": "Sendable"
        },
        {
          "kind": "text",
          "text": ", "
        },
        {
          "kind": "typeIdentifier",
          "text": "Failure"
        },
        {
          "kind": "text",
          "text": " : "
        },
        {
          "kind": "typeIdentifier",
          "preciseIdentifier": "s:s5ErrorP",
          "text": "Error"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/Swift/Task",
      "kind": "symbol",
      "role": "symbol",
      "title": "Task",
      "type": "topic",
      "url": "/documentation/Swift/Task"
    },
    "doc://com.apple.documentation/documentation/Swift/concurrency": {
      "abstract": [
        {
          "text": "Perform asynchronous and parallel operations.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/Swift/concurrency",
      "kind": "article",
      "role": "article",
      "title": "Concurrency",
      "type": "topic",
      "url": "/documentation/Swift/concurrency"
    },
    "doc://com.apple.documentation/documentation/UIKit/UIImageView": {
      "abstract": [
        {
          "text": "A view that displays a single image or a sequence of animated images in your interface.",
          "type": "text"
        }
      ],
      "fragments": [
        {
          "kind": "attribute",
          "text": "@"
        },
        {
          "kind": "attribute",
          "preciseIdentifier": "s:ScM",
          "text": "MainActor"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "keyword",
          "text": "class"
        },
        {
          "kind": "text",
          "text": " "
        },
        {
          "kind": "identifier",
          "text": "UIImageView"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/UIKit/UIImageView",
      "kind": "symbol",
      "role": "symbol",
      "title": "UIImageView",
      "type": "topic",
      "url": "/documentation/UIKit/UIImageView"
    },
    "doc://com.apple.documentation/documentation/Xcode/choosing-localization-regions-and-scripts": {
      "abstract": [
        {
          "text": "Add a language-only localization or localizations specific to regional variants and scripts.",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/Xcode/choosing-localization-regions-and-scripts",
      "kind": "article",
      "role": "article",
      "title": "Choosing localization regions and scripts",
      "type": "topic",
      "url": "/documentation/Xcode/choosing-localization-regions-and-scripts"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "abstract": [
        {
          "text": "",
          "type": "text"
        }
      ],
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "kind": "technologies",
      "role": "overview",
      "title": "Technologies",
      "type": "topic",
      "url": "/documentation/technologies"
    },
    "enabling_live_text_interactions_with_images-1": {
      "alt": "A mockup of three iPhone screens showing the Live Text button and highlighted text with its action menu, a long press of an email address with its action menu, and a long press of a QR code with its action menu.",
      "identifier": "enabling_live_text_interactions_with_images-1",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/18bb3f1f13bfb8d615897f3714d561f9/enabling_live_text_interactions_with_images-1@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/aa3902a2f859e60e45a4a50ef2c7c778/enabling_live_text_interactions_with_images-1~dark@2x.png"
        }
      ]
    },
    "enabling_live_text_interactions_with_images-2": {
      "alt": "A diagram showing an image that is offset in an arbitrary view with the overlay view on top of it.",
      "identifier": "enabling_live_text_interactions_with_images-2",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/81c2d3481475ede1fb5f15419f88f2ec/enabling_live_text_interactions_with_images-2@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/3e5c9e74162d80b0d8078bd1f1953134/enabling_live_text_interactions_with_images-2~dark@2x.png"
        }
      ]
    },
    "enabling_live_text_interactions_with_images-3": {
      "alt": "A mockup of the lower half of an iPhone screen showing the Live Text button enabled and recognized items highlighted, such as a mailing address and QR code.",
      "identifier": "enabling_live_text_interactions_with_images-3",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x",
            "light"
          ],
          "url": "https://docs-assets.developer.apple.com/published/db02b7be0de6b19bc1dd36bc19293691/enabling_live_text_interactions_with_images-3@2x.png"
        },
        {
          "traits": [
            "2x",
            "dark"
          ],
          "url": "https://docs-assets.developer.apple.com/published/d48f50114b9286330b4b9269cb498ca5/enabling_live_text_interactions_with_images-3~dark@2x.png"
        }
      ]
    }
  },
  "schemaVersion": {
    "major": 0,
    "minor": 3,
    "patch": 0
  },
  "sections": [],
  "seeAlsoSections": [
    {
      "anchor": "Content-recognition-and-interaction-in-images",
      "generated": true,
      "identifiers": [
        "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalyzer",
        "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysis",
        "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteraction",
        "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisInteractionDelegate",
        "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayView",
        "doc://com.apple.VisionKit/documentation/VisionKit/ImageAnalysisOverlayViewDelegate"
      ],
      "title": "Content recognition and interaction in images"
    }
  ],
  "variantOverrides": [
    {
      "patch": [
        {
          "op": "replace",
          "path": "/identifier/interfaceLanguage",
          "value": "occ"
        },
        {
          "op": "add",
          "path": "/topicSections",
          "value": null
        },
        {
          "op": "replace",
          "path": "/seeAlsoSections",
          "value": [
            {
              "anchor": "Content-recognition-and-interaction-in-images",
              "generated": true,
              "identifiers": [],
              "title": "Content recognition and interaction in images"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1AppKit~1NSImageView/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@interface"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "NSImageView"
            },
            {
              "kind": "text",
              "text": " : "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)NSControl",
              "text": "NSControl"
            }
          ]
        },
        {
          "op": "replace",
          "path": "/references/doc:~1~1com.apple.documentation~1documentation~1UIKit~1UIImageView/fragments",
          "value": [
            {
              "kind": "keyword",
              "text": "@interface"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "UIImageView"
            },
            {
              "kind": "text",
              "text": " : "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:objc(cs)UIView",
              "text": "UIView"
            }
          ]
        }
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ],
  "variants": [
    {
      "paths": [
        "/documentation/visionkit/enabling-live-text-interactions-with-images"
      ],
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ]
    },
    {
      "paths": [
        "/documentation/visionkit/enabling-live-text-interactions-with-images"
      ],
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ]
    }
  ]
}
